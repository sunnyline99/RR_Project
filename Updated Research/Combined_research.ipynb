{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a181cd30",
   "metadata": {},
   "source": [
    "# Spam Detection Project Reproduced One-to-One"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b60d81aa",
   "metadata": {},
   "source": [
    "# Reproducible Research Project\n",
    "\n",
    "### Jakub Cudak\n",
    "### Paulina Sereikyte\n",
    "### Dawid Szyszko-Celinski\n",
    "\n",
    "![alt text](https://www.netia.pl/Netia/media/blog/spam-co-to-jest.png)\n",
    "\n",
    "Source: https://www.netia.pl/Netia/media/blog/spam-co-to-jest.png\n",
    "\n",
    "## Aim of the initial project\n",
    "\n",
    "The main aim of the project is to reproduce the econometric project submitted for the \"Advanced Econometric\" subject. The initial project idea was to create a logit and probit econometric model in RStudio that would predict if the email is spam. The dataset used for the initial analysis mainly consisted of certain keywords frequenies in the text and additional metrics such as a number of words in the email.\n",
    "\n",
    "The approach of the modelling was as follows:\n",
    "1) Create a basic probit and logit model that consists of all explanatory variables\n",
    "2) Perform LR (likelihood Ratio) test to verify if the model`s parameters are jointly significant\n",
    "3) Perform stepwise regression for both models to remove all coefficients whose p-value is above the 5% threshold\n",
    "4) Again perform the LR test and additional Link test that would check if the model has a good specification\n",
    "5) Add interaction between variables to the analysis\n",
    "6) Perform stepwise regression\n",
    "7) Execute LR and Link test\n",
    "8) Execute the Hosmer-Lemershow test and Osjus-Rojek test to verify the specification\n",
    "9) Verify goodness of fit statistics\n",
    "10) Calculate marginal effects\n",
    "\n",
    "The whole analysis and report can be found in the \"Initial research\" file:\n",
    "1) The \"Advanced Econometrics 2022 project\" contains a report and description of the steps of the analysis\n",
    "2) \"spambase - raw data\" consists of the raw dataset used for initial analysis\n",
    "3) \"Spam detection codes\" - consist of R script used to perform the analysis\n",
    "4) \"names.csv\" is an updated file with variables names, that can be read by R studio in CSV format\n",
    "5) \"linktest.R\" and \"marginaleffects.R\" are custom functions written in R by dr Rafal Wozniak, Faculty of Economic Sciences, University of Warsaw\n",
    "\n",
    "## Aim of this project\n",
    "\n",
    "The aim of this project is to try reproducing the initial research in a different programming language - Python. We would like to verify if the actions performed in R can be easily translated into Python codes. We would like to verify if the outcomes are the same or if they differ due to possibly different algorithms that could be used in certain functions.\n",
    "\n",
    "What is more, we would like to perform the same analysis, but on a different dataset with the same keyword that was used in the initial research. Based on the new dataset new keywords will be also obtained and a new model will be produced to verify how probit and logit models will work on the different datasets and keywords. The new dataset that will be used contains only text and labels if the message is spam or not, which is why it will be necessary to perform some data transformations. The process of the initial research will be followed.\n",
    "\n",
    "In this part of the analysis we will try to recreate the previous research on the new data directly. We use an Email Spam Detection Dataset, which is available on Kaggle, and can be accessed via: https://www.kaggle.com/datasets/shantanudhakadd/email-spam-detection-dataset-classification\n",
    "\n",
    "The dataset contains 5169 unique observations, out of which 87% are non-spam emails, while only 13% are classified as spam. While split is more challenging in terms of training our models, we can expect results to be less accurate. The e-mails in the dataset are not\n",
    "\n",
    "The whole analysis can be found in the \"Updated Research\" file:\n",
    "1) \"Combined research\" consists of a report and codes in jupyter notebook that contains all codes necessary to recreate initial research one-to-one and 2 updated versions: with old and new keywords on the new dataset.\n",
    "2) \"new_data_new_words.csv\" dataset that will be used to analyse new keywords on a new dataset\n",
    "3) \"new_data_old_words.csv\" dataset that will be used to analyse old keywords on a new dataset\n",
    "4) \"Technical\" folder that contains all codes that were used as technical parts to create the main file \"Combined research\"\n",
    "5) \"Link to the dataset\" - a text file containing a link to the new dataset\n",
    "\n",
    "## General results\n",
    "\n",
    "We were able to replicate the analysis, which was originally designed in R, in Python. Some adjustments had to be made to create new formulas and utilise a different set of packages, however the results generated in Python were the same as the results generated in R when using the same dataset.\n",
    "\n",
    "Applying the same methodologies to a new dataset were more challenging, as the initial analysis was based on the word frequencies of certain words in the text. At first, the analysis was conducted based on the most common words and characters present in the new dataset. Then the models were replicated by calculating the frequencies of the words from the initial word list. \n",
    "While it was still possible to construct the models, they were generally less efficient in detecting spam. One of the main reasons was the much lower frequencies of the selected and previously used words in the new text. This resulted in very low variances within the variable which then had to be removed to be included in the models.\n",
    "This issue was more prevalent when trying to replicate the analysis using the old word list - many of the words were highly specific to the initial dataset and thus were not found in the new data. This resulted in a big reduction in the number of variables and possible interactions, therefore the analysis could not be replicated exactly.\n",
    "\n",
    "Overall, this excercise has proven what has been discussed in the initial research report- while econometric analysis performed well or on par with more complex models, it was determined to be highly specific to the data it was built on. As spam detection is a fast evolving subject that would need frequent updating and flexibility, other models, such as machine learning, are preferable.\n",
    "\n",
    "## Disclaimer: AI Tools were used to reproduce the research\n",
    "\n",
    "Our translation from R to Python was aided by the use of ChatGPT. The process involved an initial machine translation, after which we have fixed mistakes in subsequent iterations. ChatGPT provided also an alternative to Stack Overflow while searching for solutions to bugs we encountered. While using ChatGPT we have used queries that contained R code and the error messages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eff7ca13",
   "metadata": {},
   "source": [
    "Load the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf0eb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import patsy\n",
    "from statsmodels.discrete.discrete_model import ProbitResults, LogitResults\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import norm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1497ff39",
   "metadata": {},
   "source": [
    "Import the initial dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20412dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"/Inital research/spambase.data\", header=None)\n",
    "names = pd.read_csv(\"names.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2f3f7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of         0     1     2    3     4     5     6     7     8     9   ...     48  \\\n",
       "0     0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "1     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
       "2     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
       "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "4     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "4596  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4597  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4598  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
       "4599  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4600  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "\n",
       "         49   50     51     52     53     54   55    56  57  \n",
       "0     0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1     0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2     0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3     0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4     0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "...     ...  ...    ...    ...    ...    ...  ...   ...  ..  \n",
       "4596  0.232  0.0  0.000  0.000  0.000  1.142    3    88   0  \n",
       "4597  0.000  0.0  0.353  0.000  0.000  1.555    4    14   0  \n",
       "4598  0.718  0.0  0.000  0.000  0.000  1.404    6   118   0  \n",
       "4599  0.057  0.0  0.000  0.000  0.000  1.147    5    78   0  \n",
       "4600  0.000  0.0  0.125  0.000  0.000  1.250    5    40   0  \n",
       "\n",
       "[4601 rows x 58 columns]>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "251713ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                              0\n",
       "0               word_freq_make\n",
       "1            word_freq_address\n",
       "2                word_freq_all\n",
       "3                 word_freq_3d\n",
       "4                word_freq_our\n",
       "5               word_freq_over\n",
       "6             word_freq_remove\n",
       "7           word_freq_internet\n",
       "8              word_freq_order\n",
       "9               word_freq_mail\n",
       "10           word_freq_receive\n",
       "11              word_freq_will\n",
       "12            word_freq_people\n",
       "13            word_freq_report\n",
       "14         word_freq_addresses\n",
       "15              word_freq_free\n",
       "16          word_freq_business\n",
       "17             word_freq_email\n",
       "18               word_freq_you\n",
       "19            word_freq_credit\n",
       "20              word_freq_your\n",
       "21              word_freq_font\n",
       "22               word_freq_000\n",
       "23             word_freq_money\n",
       "24                word_freq_hp\n",
       "25               word_freq_hpl\n",
       "26            word_freq_george\n",
       "27               word_freq_650\n",
       "28               word_freq_lab\n",
       "29              word_freq_labs\n",
       "30            word_freq_telnet\n",
       "31               word_freq_857\n",
       "32              word_freq_data\n",
       "33               word_freq_415\n",
       "34                word_freq_85\n",
       "35        word_freq_technology\n",
       "36              word_freq_1999\n",
       "37             word_freq_parts\n",
       "38                word_freq_pm\n",
       "39            word_freq_direct\n",
       "40                word_freq_cs\n",
       "41           word_freq_meeting\n",
       "42          word_freq_original\n",
       "43           word_freq_project\n",
       "44                word_freq_re\n",
       "45               word_freq_edu\n",
       "46             word_freq_table\n",
       "47        word_freq_conference\n",
       "48                 char_freq_;\n",
       "49                 char_freq_(\n",
       "50                 char_freq_[\n",
       "51                 char_freq_!\n",
       "52                 char_freq_$\n",
       "53                 char_freq_#\n",
       "54  capital_run_length_average\n",
       "55  capital_run_length_longest\n",
       "56    capital_run_length_total>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e25ea9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "\n",
    "names.loc[48, 0] = \"char_freq_semicolon\"\n",
    "names.loc[49, 0] = \"char_freq_bracket\"\n",
    "names.loc[50, 0] = \"char_freq_square_bracket\"\n",
    "names.loc[51, 0] = \"char_freq_exclamation\"\n",
    "names.loc[52, 0] = \"char_freq_dollar\"\n",
    "names.loc[53, 0] = \"char_freq_hashtag\"\n",
    "names.loc[57, 0] = \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e08fef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove missing values\n",
    "\n",
    "spam.columns = names[0].values\n",
    "\n",
    "spam.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7daf3969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
       "       'word_freq_our', 'word_freq_over', 'word_freq_remove',\n",
       "       'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
       "       'word_freq_receive', 'word_freq_will', 'word_freq_people',\n",
       "       'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
       "       'word_freq_business', 'word_freq_email', 'word_freq_you',\n",
       "       'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n",
       "       'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n",
       "       'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n",
       "       'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
       "       'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n",
       "       'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n",
       "       'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
       "       'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
       "       'char_freq_semicolon', 'char_freq_bracket', 'char_freq_square_bracket',\n",
       "       'char_freq_exclamation', 'char_freq_dollar', 'char_freq_hashtag',\n",
       "       'capital_run_length_average', 'capital_run_length_longest',\n",
       "       'capital_run_length_total', 'spam'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overview of our database\n",
    "\n",
    "spam.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d595875b",
   "metadata": {},
   "source": [
    "Let us check the distribution of spam and non-spam mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea06ef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spam_count = spam[\"spam\"].value_counts()\n",
    "perc_yes = round(spam_count[1] / len(spam) * 100, 2)\n",
    "perc_no = round(spam_count[0] / len(spam) * 100, 2)\n",
    "\n",
    "plt.bar([\"Non-spam\", \"Spam\"], spam_count, color=[\"#31d64f\", \"#ed3b3b\"])\n",
    "plt.title(\"Number of spam/non-spam mails\")\n",
    "plt.xlabel(\"Type of mail\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend([\"Non-spam\", \"Spam\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "207735ce",
   "metadata": {},
   "source": [
    "We see that the dataset consists of 1813 observations in the “spam” category and 2788 in the “non-spam” category, providing a ca. 40/60 class distribution. Moreover, there are no missing values in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4d25fc9",
   "metadata": {},
   "source": [
    "## Start from the most general model that contains all explanatory variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "451d0fa9",
   "metadata": {},
   "source": [
    "Create a formula that consists of all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b02c215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"spam ~ \" + \" + \".join(spam.columns[:-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "246073b9",
   "metadata": {},
   "source": [
    "We build two classification models, probit and logit, both binary dependent variable predictive models. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52ffe5b2",
   "metadata": {},
   "source": [
    "Probit inital model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f4781df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207573\n",
      "         Iterations 15\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 4601\n",
      "Model:                         Probit   Df Residuals:                     4543\n",
      "Method:                           MLE   Df Model:                           57\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.6904\n",
      "Time:                        22:37:48   Log-Likelihood:                -955.04\n",
      "converged:                       True   LL-Null:                       -3085.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================================\n",
      "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                     -0.8356      0.075    -11.098      0.000      -0.983      -0.688\n",
      "word_freq_make                -0.1751      0.115     -1.520      0.128      -0.401       0.051\n",
      "word_freq_address             -0.0858      0.035     -2.462      0.014      -0.154      -0.017\n",
      "word_freq_all                  0.1134      0.063      1.803      0.071      -0.010       0.237\n",
      "word_freq_3d                   1.3766      0.803      1.713      0.087      -0.198       2.951\n",
      "word_freq_our                  0.3122      0.047      6.652      0.000       0.220       0.404\n",
      "word_freq_over                 0.4709      0.108      4.363      0.000       0.259       0.683\n",
      "word_freq_remove               0.9894      0.121      8.146      0.000       0.751       1.227\n",
      "word_freq_internet             0.2829      0.080      3.534      0.000       0.126       0.440\n",
      "word_freq_order                0.2988      0.120      2.493      0.013       0.064       0.534\n",
      "word_freq_mail                 0.0786      0.039      2.033      0.042       0.003       0.154\n",
      "word_freq_receive             -0.0800      0.151     -0.531      0.595      -0.375       0.215\n",
      "word_freq_will                -0.0867      0.041     -2.129      0.033      -0.167      -0.007\n",
      "word_freq_people              -0.0279      0.126     -0.221      0.825      -0.276       0.220\n",
      "word_freq_report               0.1086      0.078      1.396      0.163      -0.044       0.261\n",
      "word_freq_addresses            0.8329      0.362      2.298      0.022       0.122       1.543\n",
      "word_freq_free                 0.5191      0.062      8.437      0.000       0.399       0.640\n",
      "word_freq_business             0.4645      0.109      4.248      0.000       0.250       0.679\n",
      "word_freq_email                0.1029      0.064      1.595      0.111      -0.024       0.229\n",
      "word_freq_you                  0.0401      0.019      2.079      0.038       0.002       0.078\n",
      "word_freq_credit               0.4384      0.211      2.079      0.038       0.025       0.852\n",
      "word_freq_your                 0.1487      0.028      5.359      0.000       0.094       0.203\n",
      "word_freq_font                 0.1434      0.087      1.652      0.098      -0.027       0.313\n",
      "word_freq_000                  1.2991      0.212      6.142      0.000       0.885       1.714\n",
      "word_freq_money                0.2165      0.062      3.466      0.001       0.094       0.339\n",
      "word_freq_hp                  -0.7846      0.108     -7.271      0.000      -0.996      -0.573\n",
      "word_freq_hpl                 -0.6996      0.200     -3.505      0.000      -1.091      -0.308\n",
      "word_freq_george              -3.5943      0.564     -6.370      0.000      -4.700      -2.488\n",
      "word_freq_650                  0.2448      0.101      2.421      0.015       0.047       0.443\n",
      "word_freq_lab                 -1.4529      0.775     -1.874      0.061      -2.972       0.067\n",
      "word_freq_labs                -0.2275      0.166     -1.375      0.169      -0.552       0.097\n",
      "word_freq_telnet              -0.0992      0.231     -0.429      0.668      -0.553       0.354\n",
      "word_freq_857                  1.1786      1.536      0.767      0.443      -1.832       4.189\n",
      "word_freq_data                -0.4158      0.161     -2.590      0.010      -0.730      -0.101\n",
      "word_freq_415                 -0.2320      0.819     -0.283      0.777      -1.837       1.373\n",
      "word_freq_85                  -1.2428      0.406     -3.060      0.002      -2.039      -0.447\n",
      "word_freq_technology           0.4606      0.161      2.860      0.004       0.145       0.776\n",
      "word_freq_1999                 0.0014      0.097      0.014      0.989      -0.188       0.191\n",
      "word_freq_parts               -0.3007      0.227     -1.324      0.185      -0.746       0.144\n",
      "word_freq_pm                  -0.4698      0.208     -2.255      0.024      -0.878      -0.061\n",
      "word_freq_direct              -0.1422      0.201     -0.708      0.479      -0.536       0.251\n",
      "word_freq_cs                 -24.2110     13.248     -1.828      0.068     -50.177       1.755\n",
      "word_freq_meeting             -1.5055      0.431     -3.496      0.000      -2.350      -0.662\n",
      "word_freq_original            -0.6552      0.400     -1.640      0.101      -1.438       0.128\n",
      "word_freq_project             -0.8125      0.264     -3.081      0.002      -1.329      -0.296\n",
      "word_freq_re                  -0.4094      0.074     -5.507      0.000      -0.555      -0.264\n",
      "word_freq_edu                 -0.6755      0.114     -5.923      0.000      -0.899      -0.452\n",
      "word_freq_table               -1.2250      0.764     -1.604      0.109      -2.722       0.272\n",
      "word_freq_conference          -2.0125      0.746     -2.699      0.007      -3.474      -0.551\n",
      "char_freq_semicolon           -0.8079      0.248     -3.257      0.001      -1.294      -0.322\n",
      "char_freq_bracket             -0.1302      0.139     -0.933      0.351      -0.404       0.143\n",
      "char_freq_square_bracket      -0.4066      0.452     -0.899      0.369      -1.293       0.480\n",
      "char_freq_exclamation          0.1572      0.027      5.901      0.000       0.105       0.209\n",
      "char_freq_dollar               2.2585      0.283      7.994      0.000       1.705       2.812\n",
      "char_freq_hashtag              1.3189      0.329      4.012      0.000       0.675       1.963\n",
      "capital_run_length_average    -0.0027      0.008     -0.333      0.739      -0.019       0.013\n",
      "capital_run_length_longest     0.0043      0.001      3.595      0.000       0.002       0.007\n",
      "capital_run_length_total       0.0005   9.83e-05      5.006      0.000       0.000       0.001\n",
      "==============================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.33 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "myprobit = sm.Probit.from_formula(formula, data=spam).fit()\n",
    "print(myprobit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5a94060",
   "metadata": {},
   "source": [
    "Logit initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69db3ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197323\n",
      "         Iterations 15\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 4601\n",
      "Model:                          Logit   Df Residuals:                     4543\n",
      "Method:                           MLE   Df Model:                           57\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.7057\n",
      "Time:                        22:37:49   Log-Likelihood:                -907.88\n",
      "converged:                       True   LL-Null:                       -3085.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================================\n",
      "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                     -1.5686      0.142    -11.044      0.000      -1.847      -1.290\n",
      "word_freq_make                -0.3895      0.231     -1.683      0.092      -0.843       0.064\n",
      "word_freq_address             -0.1458      0.069     -2.104      0.035      -0.282      -0.010\n",
      "word_freq_all                  0.1141      0.110      1.035      0.301      -0.102       0.330\n",
      "word_freq_3d                   2.2515      1.507      1.494      0.135      -0.702       5.205\n",
      "word_freq_our                  0.5624      0.102      5.524      0.000       0.363       0.762\n",
      "word_freq_over                 0.8830      0.250      3.534      0.000       0.393       1.373\n",
      "word_freq_remove               2.2785      0.333      6.846      0.000       1.626       2.931\n",
      "word_freq_internet             0.5696      0.168      3.387      0.001       0.240       0.899\n",
      "word_freq_order                0.7343      0.285      2.577      0.010       0.176       1.293\n",
      "word_freq_mail                 0.1275      0.073      1.755      0.079      -0.015       0.270\n",
      "word_freq_receive             -0.2557      0.298     -0.858      0.391      -0.840       0.328\n",
      "word_freq_will                -0.1383      0.074     -1.868      0.062      -0.283       0.007\n",
      "word_freq_people              -0.0796      0.230     -0.346      0.730      -0.531       0.372\n",
      "word_freq_report               0.1447      0.136      1.061      0.289      -0.123       0.412\n",
      "word_freq_addresses            1.2362      0.725      1.704      0.088      -0.186       2.658\n",
      "word_freq_free                 1.0386      0.146      7.128      0.000       0.753       1.324\n",
      "word_freq_business             0.9599      0.225      4.264      0.000       0.519       1.401\n",
      "word_freq_email                0.1203      0.117      1.027      0.305      -0.109       0.350\n",
      "word_freq_you                  0.0813      0.035      2.320      0.020       0.013       0.150\n",
      "word_freq_credit               1.0474      0.538      1.946      0.052      -0.008       2.102\n",
      "word_freq_your                 0.2419      0.052      4.615      0.000       0.139       0.345\n",
      "word_freq_font                 0.2013      0.163      1.238      0.216      -0.117       0.520\n",
      "word_freq_000                  2.2452      0.471      4.762      0.000       1.321       3.169\n",
      "word_freq_money                0.4264      0.162      2.630      0.009       0.109       0.744\n",
      "word_freq_hp                  -1.9204      0.313     -6.139      0.000      -2.534      -1.307\n",
      "word_freq_hpl                 -1.0402      0.440     -2.366      0.018      -1.902      -0.179\n",
      "word_freq_george             -11.7672      2.113     -5.569      0.000     -15.909      -7.626\n",
      "word_freq_650                  0.4454      0.199      2.237      0.025       0.055       0.836\n",
      "word_freq_lab                 -2.4864      1.502     -1.656      0.098      -5.429       0.457\n",
      "word_freq_labs                -0.3299      0.314     -1.052      0.293      -0.945       0.285\n",
      "word_freq_telnet              -0.1702      0.482     -0.353      0.724      -1.114       0.774\n",
      "word_freq_857                  2.5488      3.283      0.776      0.438      -3.886       8.984\n",
      "word_freq_data                -0.7383      0.312     -2.369      0.018      -1.349      -0.127\n",
      "word_freq_415                  0.6679      1.601      0.417      0.676      -2.469       3.805\n",
      "word_freq_85                  -2.0554      0.788     -2.607      0.009      -3.601      -0.510\n",
      "word_freq_technology           0.9237      0.309      2.989      0.003       0.318       1.530\n",
      "word_freq_1999                 0.0465      0.175      0.265      0.791      -0.297       0.390\n",
      "word_freq_parts               -0.5968      0.423     -1.410      0.158      -1.426       0.233\n",
      "word_freq_pm                  -0.8650      0.383     -2.260      0.024      -1.615      -0.115\n",
      "word_freq_direct              -0.3046      0.364     -0.838      0.402      -1.017       0.408\n",
      "word_freq_cs                 -45.0480     26.600     -1.694      0.090     -97.182       7.086\n",
      "word_freq_meeting             -2.6887      0.838     -3.207      0.001      -4.332      -1.045\n",
      "word_freq_original            -1.2471      0.806     -1.547      0.122      -2.828       0.333\n",
      "word_freq_project             -1.5732      0.529     -2.973      0.003      -2.610      -0.536\n",
      "word_freq_re                  -0.7923      0.156     -5.091      0.000      -1.097      -0.487\n",
      "word_freq_edu                 -1.4592      0.269     -5.434      0.000      -1.986      -0.933\n",
      "word_freq_table               -2.3259      1.659     -1.402      0.161      -5.578       0.926\n",
      "word_freq_conference          -4.0156      1.611     -2.493      0.013      -7.173      -0.858\n",
      "char_freq_semicolon           -1.2911      0.442     -2.920      0.004      -2.158      -0.424\n",
      "char_freq_bracket             -0.1881      0.249     -0.754      0.451      -0.677       0.301\n",
      "char_freq_square_bracket      -0.6574      0.838     -0.784      0.433      -2.301       0.986\n",
      "char_freq_exclamation          0.3472      0.089      3.890      0.000       0.172       0.522\n",
      "char_freq_dollar               5.3360      0.706      7.553      0.000       3.951       6.721\n",
      "char_freq_hashtag              2.4032      1.113      2.159      0.031       0.221       4.585\n",
      "capital_run_length_average     0.0120      0.019      0.636      0.525      -0.025       0.049\n",
      "capital_run_length_longest     0.0091      0.003      3.618      0.000       0.004       0.014\n",
      "capital_run_length_total       0.0008      0.000      3.747      0.000       0.000       0.001\n",
      "==============================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.28 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "mylogit = sm.Logit.from_formula(formula, data=spam).fit()\n",
    "print(mylogit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "433aef44",
   "metadata": {},
   "source": [
    "# Significance test of models coeeficients - LR test\n",
    "\n",
    "H0: Beta1 = 0 & Beta2 = 0 & … & Beta57 = 0 (the general model can be simplified to restricted model based only on constant / all Betas are jointly insignificant)\n",
    "H1: The general model cannot be simplified to a restricted model. All Betas are jointly significant.\n",
    "\n",
    "Both models p-values are 0, so null hypothesis can be rejected. It means that for both models, the coefficients are jointly significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3af6d927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670523\n",
      "         Iterations 4\n",
      "Probit likelihood ratio test p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "null_probit = sm.Probit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam)))).fit()\n",
    "probit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probit likelihood ratio test p-value:\", probit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb8447e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670523\n",
      "         Iterations 4\n",
      "Logit likelihood ratio test p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "null_logit = sm.Logit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam)))).fit()\n",
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68ab87c0",
   "metadata": {},
   "source": [
    "## Stepwise regression\n",
    "\n",
    "As not all variables are individually significant, we perform the stepwise regression, which removes variables below the 5% significance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f50e6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_1999\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207573\n",
      "         Iterations 15\n",
      "2024.088917331387\n",
      "word_freq_people\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207579\n",
      "         Iterations 15\n",
      "2022.1381806395907\n",
      "word_freq_415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207587\n",
      "         Iterations 15\n",
      "2020.2155613834486\n",
      "capital_run_length_average\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207597\n",
      "         Iterations 15\n",
      "2018.3090124810756\n",
      "word_freq_telnet\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207632\n",
      "         Iterations 15\n",
      "2016.6278326615745\n",
      "word_freq_receive\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207662\n",
      "         Iterations 15\n",
      "2014.9078328699995\n",
      "word_freq_direct\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207723\n",
      "         Iterations 15\n",
      "2013.4677960927206\n",
      "word_freq_857\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207781\n",
      "         Iterations 15\n",
      "2011.9973433071923\n",
      "char_freq_bracket\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207870\n",
      "         Iterations 15\n",
      "2010.8215432666034\n",
      "char_freq_square_bracket\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.208013\n",
      "         Iterations 15\n",
      "2010.1315739685158\n",
      "word_freq_parts\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.208293\n",
      "         Iterations 15\n",
      "2010.7134011600897\n",
      "word_freq_labs\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.208496\n",
      "         Iterations 15\n",
      "2010.5829619277797\n",
      "word_freq_report\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.208711\n",
      "         Iterations 15\n",
      "2010.5603090443033\n",
      "word_freq_table\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.209245\n",
      "         Iterations 15\n",
      "2013.470853221295\n",
      "word_freq_email\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.209514\n",
      "         Iterations 15\n",
      "2013.9508016037705\n",
      "word_freq_original\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.209999\n",
      "         Iterations 15\n",
      "2016.412114345779\n",
      "word_freq_3d\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.211320\n",
      "         Iterations 15\n",
      "2026.567296884151\n",
      "word_freq_font\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.211849\n",
      "         Iterations 15\n",
      "2029.4377589667429\n",
      "word_freq_all\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.212171\n",
      "         Iterations 15\n",
      "2030.398643225174\n",
      "word_freq_mail\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.212520\n",
      "         Iterations 15\n",
      "2031.6074027190002\n",
      "word_freq_cs\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.215982\n",
      "         Iterations 13\n",
      "2061.4663901491\n",
      "word_freq_lab\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.217255\n",
      "         Iterations 13\n",
      "2071.1786079184076\n",
      "word_freq_make\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.217638\n",
      "         Iterations 13\n",
      "2072.7084984515222\n"
     ]
    }
   ],
   "source": [
    "p_probit = myprobit.pvalues\n",
    "spam_temp_probit = spam.copy()\n",
    "\n",
    "while any(p_probit > 0.05):\n",
    "    worstp = p_probit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_probit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_probit.columns[:-1]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    myprobit = sm.Probit.from_formula(formula, data=spam_temp_probit).fit()\n",
    "    p_probit = myprobit.pvalues\n",
    "    print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09ce8b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_1999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197330\n",
      "         Iterations 15\n",
      "1929.8351001472463\n",
      "word_freq_telnet\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197358\n",
      "         Iterations 15\n",
      "1928.0866448894978\n",
      "word_freq_people\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197372\n",
      "         Iterations 15\n",
      "1926.2137629946117\n",
      "word_freq_415\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197392\n",
      "         Iterations 15\n",
      "1924.4056155735882\n",
      "capital_run_length_average\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197440\n",
      "         Iterations 15\n",
      "1922.846172866969\n",
      "char_freq_bracket\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197500\n",
      "         Iterations 15\n",
      "1921.3991742674934\n",
      "word_freq_857\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197573\n",
      "         Iterations 15\n",
      "1920.0647903082443\n",
      "char_freq_square_bracket\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197678\n",
      "         Iterations 15\n",
      "1919.0337948154875\n",
      "word_freq_direct\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197763\n",
      "         Iterations 15\n",
      "1917.8151918506705\n",
      "word_freq_receive\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197849\n",
      "         Iterations 15\n",
      "1916.6081205165324\n",
      "word_freq_email\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197952\n",
      "         Iterations 15\n",
      "1915.5504717918839\n",
      "word_freq_report\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.198051\n",
      "         Iterations 15\n",
      "1914.4675229356426\n",
      "word_freq_labs\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.198186\n",
      "         Iterations 15\n",
      "1913.7108461065413\n",
      "word_freq_all\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.198313\n",
      "         Iterations 15\n",
      "1912.8758937291022\n",
      "word_freq_table\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.198761\n",
      "         Iterations 15\n",
      "1914.9965439222237\n",
      "word_freq_font\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.199029\n",
      "         Iterations 15\n",
      "1915.4664193981243\n",
      "word_freq_parts\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.199435\n",
      "         Iterations 15\n",
      "1917.1989978378258\n",
      "word_freq_3d\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.200416\n",
      "         Iterations 15\n",
      "1924.2281989342282\n",
      "word_freq_original\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.200923\n",
      "         Iterations 15\n",
      "1926.890731198925\n",
      "word_freq_lab\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.201978\n",
      "         Iterations 15\n",
      "1934.5974196686414\n",
      "word_freq_mail\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.202278\n",
      "         Iterations 15\n",
      "1935.3616724448575\n",
      "word_freq_cs\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.205096\n",
      "         Iterations 13\n",
      "1959.2969039457766\n",
      "word_freq_will\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.205470\n",
      "         Iterations 13\n",
      "1960.7358706869513\n",
      "word_freq_addresses\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.205945\n",
      "         Iterations 13\n",
      "1963.1088921606406\n"
     ]
    }
   ],
   "source": [
    "p_logit = mylogit.pvalues\n",
    "spam_temp_logit = spam.copy()\n",
    "\n",
    "while any(p_logit > 0.05):\n",
    "    worstp = p_logit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_logit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_logit.columns[:-1]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    mylogit = sm.Logit.from_formula(formula, data=spam_temp_logit).fit()\n",
    "    p_logit = mylogit.pvalues\n",
    "    print(mylogit.aic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "415ba833",
   "metadata": {},
   "source": [
    "## Link test - it verifies the model specification\n",
    "\n",
    "If yhat is significant and yhat2 is not signifficant: model has a good specification\n",
    "\n",
    "If yhat is / is not significant and yhat2 is signifficant: model does not have a good specification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b316024b",
   "metadata": {},
   "source": [
    "The defined functions were recreated from R codes that can be found in the \"Initial Research\" folder on GitHub. The functions were written by dr Rafal Wozniak, Faculty of Economic Sciences, University of Warsaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a7e8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linktest_probit(model):\n",
    "    \"\"\"\n",
    "    Function to perform linktest on a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "    - model: logistic regression model object\n",
    "    \n",
    "    Returns:\n",
    "    - aux_reg: auxiliary regression model object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the data\n",
    "    y = model.model.endog\n",
    "    pred = model.predict()\n",
    "    pred = np.clip(pred, 1e-12, 1 - 1e-12)\n",
    "    yhat = np.log(pred/(1-pred))\n",
    "    yhat2 = yhat**2\n",
    "\n",
    "    # Add constant column to predictor variables\n",
    "    X = np.column_stack((np.ones_like(y), yhat, yhat2))\n",
    "\n",
    "    # Remove rows with missing or infinite values\n",
    "    valid_idx = np.isfinite(X).all(axis=1)\n",
    "    X = X[valid_idx]\n",
    "    y = y[valid_idx]\n",
    "\n",
    "    # Fit the binomial regression model\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial(link=sm.genmod.families.links.probit()))\n",
    "    result = model.fit()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e1be571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linktest_logit(model):\n",
    "    \"\"\"\n",
    "    Function to perform linktest on a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "    - model: logistic regression model object\n",
    "    \n",
    "    Returns:\n",
    "    - aux_reg: auxiliary regression model object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the data\n",
    "    y = model.model.endog\n",
    "    pred = model.predict()\n",
    "    pred = np.clip(pred, 1e-12, 1 - 1e-12)\n",
    "    yhat = np.log(pred/(1-pred))\n",
    "    yhat2 = yhat**2\n",
    "\n",
    "    # Add constant column to predictor variables\n",
    "    X = np.column_stack((np.ones_like(y), yhat, yhat2))\n",
    "\n",
    "    # Remove rows with missing or infinite values\n",
    "    valid_idx = np.isfinite(X).all(axis=1)\n",
    "    X = X[valid_idx]\n",
    "    y = y[valid_idx]\n",
    "\n",
    "    # Fit the binomial regression model\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial(link=sm.genmod.families.links.logit()))\n",
    "    result = model.fit()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aad47d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 4601\n",
      "Model:                            GLM   Df Residuals:                     4598\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       34907.\n",
      "Time:                        22:38:17   Pearson chi2:                 1.71e+18\n",
      "No. Iterations:                   100   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -4.972e+12    1.4e+05  -3.54e+07      0.000   -4.97e+12   -4.97e+12\n",
      "x1          2.363e+13   1.21e+04   1.95e+09      0.000    2.36e+13    2.36e+13\n",
      "x2          2.199e+11    536.177    4.1e+08      0.000     2.2e+11     2.2e+11\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1014: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1014: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "# Linktest for probit model - after stepwise regression\n",
    "linktest_result_probit = linktest_probit(myprobit)\n",
    "print(linktest_result_probit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cdcefa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 4601\n",
      "Model:                            GLM   Df Residuals:                     4598\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -940.83\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       1881.7\n",
      "Time:                        22:38:17   Pearson chi2:                 7.32e+09\n",
      "No. Iterations:                    16   Pseudo R-squ. (CS):             0.6063\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0902      0.060      1.501      0.133      -0.028       0.208\n",
      "x1             1.0204      0.036     28.024      0.000       0.949       1.092\n",
      "x2            -0.0319      0.004     -8.966      0.000      -0.039      -0.025\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Linktest for logit model - after stepwise regression\n",
    "linktest_result_logit = linktest_logit(mylogit)\n",
    "print(linktest_result_logit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42a2b95a",
   "metadata": {},
   "source": [
    "Based on the previousle mentioned criteria both model does not have good specification. The results are the same as in R.\n",
    "\n",
    "The next thing to consider is adding interaction terms to the models, so that it may help with the correct specification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "530c1348",
   "metadata": {},
   "source": [
    "### Interaction terms\n",
    "Adding interaction terms and deleting insignificant ones for probit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d94c22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                                                                       2.345811e-40\n",
      "word_freq_make                                                                  3.224714e-03\n",
      "word_freq_address                                                               4.307141e-02\n",
      "word_freq_make:word_freq_address                                                8.881067e-01\n",
      "word_freq_our                                                                   2.474520e-06\n",
      "                                                                                    ...     \n",
      "char_freq_semicolon:char_freq_dollar:char_freq_hashtag                          5.911354e-01\n",
      "char_freq_exclamation:char_freq_dollar:char_freq_hashtag                        8.673990e-01\n",
      "char_freq_semicolon:char_freq_exclamation:char_freq_dollar:char_freq_hashtag    4.725009e-01\n",
      "capital_run_length_longest                                                      1.011262e-11\n",
      "capital_run_length_total                                                        2.849669e-03\n",
      "Length: 61, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "formula_interactions = \"spam ~ word_freq_make * word_freq_address * word_freq_our + word_freq_over + word_freq_remove + word_freq_internet * word_freq_order * word_freq_free * word_freq_business + word_freq_you + word_freq_credit * word_freq_your + word_freq_000 + word_freq_money + word_freq_hp + word_freq_hpl + word_freq_george + word_freq_650 + word_freq_data + word_freq_85 + word_freq_technology + word_freq_pm + word_freq_meeting + word_freq_project + word_freq_re + word_freq_edu + word_freq_conference + char_freq_semicolon * char_freq_exclamation * char_freq_dollar * char_freq_hashtag + capital_run_length_longest + capital_run_length_total\"\n",
    "\n",
    "mylogit = sm.formula.glm(formula_interactions, data=spam, family=sm.families.Binomial(sm.genmod.families.links.logit())).fit()\n",
    "\n",
    "p = mylogit.pvalues\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a25a7e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make:word_freq_address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make:word_freq_address\n",
      "1920.299552620765\n",
      "word_freq_free:word_freq_business\n",
      "1918.3214384510645\n",
      "char_freq_exclamation:char_freq_dollar:char_freq_hashtag\n",
      "1916.348191039537\n",
      "char_freq_dollar:char_freq_hashtag\n",
      "1914.4148815341832\n",
      "word_freq_internet:word_freq_order\n",
      "1912.4856492302165\n",
      "char_freq_semicolon:char_freq_dollar\n",
      "1910.5750425935366\n",
      "char_freq_semicolon\n",
      "1908.6438618622913\n",
      "word_freq_internet:word_freq_order:word_freq_free\n",
      "1907.0447361830134\n",
      "word_freq_order:word_freq_free:word_freq_business\n",
      "1905.190842218639\n",
      "char_freq_semicolon:char_freq_exclamation:char_freq_hashtag\n",
      "1903.310937284863\n",
      "word_freq_internet:word_freq_order:word_freq_free:word_freq_business\n",
      "1902.5509796521967\n",
      "char_freq_semicolon:char_freq_dollar:char_freq_hashtag\n",
      "1904.0768697569106\n",
      "word_freq_internet:word_freq_free:word_freq_business\n",
      "1902.9043406399896\n",
      "word_freq_make:word_freq_address:word_freq_our\n",
      "1901.8527243664184\n",
      "word_freq_internet:word_freq_order:word_freq_business\n",
      "1902.6999170599224\n",
      "word_freq_internet:word_freq_business\n",
      "1900.9356701267802\n",
      "char_freq_semicolon:char_freq_exclamation:char_freq_dollar\n",
      "1901.7231435100807\n",
      "char_freq_semicolon:char_freq_exclamation:char_freq_dollar:char_freq_hashtag\n",
      "1899.7247495339152\n",
      "char_freq_exclamation:char_freq_hashtag\n",
      "1903.578313488078\n",
      "word_freq_make:word_freq_our\n",
      "1904.9415055038694\n",
      "word_freq_internet:word_freq_free\n",
      "1907.0817098338614\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        X = patsy.dmatrix(formula_interactions, data=spam)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        X = X.drop(worstp, axis=1)\n",
    "        X_names = ['Intercept'] + list(X.columns)[1:]\n",
    "        X.columns = X_names\n",
    "\n",
    "        mylogit = sm.GLM(spam['spam'], X, family=sm.families.Binomial(sm.families.links.logit())).fit()\n",
    "\n",
    "        p = mylogit.pvalues\n",
    "        print(mylogit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c174e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 4601\n",
      "Model:                            GLM   Df Residuals:                     4561\n",
      "Model Family:                Binomial   Df Model:                           39\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -913.54\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       1827.1\n",
      "Time:                        22:38:29   Pearson chi2:                 3.35e+06\n",
      "No. Iterations:                    12   Pseudo R-squ. (CS):             0.6109\n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================================\n",
      "                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    -1.6595      0.121    -13.711      0.000      -1.897      -1.422\n",
      "word_freq_make                               -0.5586      0.222     -2.516      0.012      -0.994      -0.124\n",
      "word_freq_address                            -0.1505      0.075     -2.009      0.045      -0.297      -0.004\n",
      "word_freq_our                                 0.5501      0.103      5.347      0.000       0.348       0.752\n",
      "word_freq_address:word_freq_our               1.1544      0.462      2.497      0.013       0.248       2.060\n",
      "word_freq_over                                0.7901      0.248      3.189      0.001       0.305       1.276\n",
      "word_freq_remove                              2.4200      0.338      7.163      0.000       1.758       3.082\n",
      "word_freq_internet                            0.5753      0.158      3.645      0.000       0.266       0.885\n",
      "word_freq_order                               1.3900      0.318      4.378      0.000       0.768       2.012\n",
      "word_freq_free                                1.0134      0.143      7.073      0.000       0.733       1.294\n",
      "word_freq_order:word_freq_free               -1.3862      0.690     -2.008      0.045      -2.739      -0.033\n",
      "word_freq_business                            1.1386      0.231      4.927      0.000       0.686       1.592\n",
      "word_freq_order:word_freq_business           -0.8560      0.173     -4.937      0.000      -1.196      -0.516\n",
      "word_freq_you                                 0.0876      0.034      2.552      0.011       0.020       0.155\n",
      "word_freq_credit                              1.8744      0.643      2.914      0.004       0.614       3.135\n",
      "word_freq_your                                0.2142      0.048      4.422      0.000       0.119       0.309\n",
      "word_freq_credit:word_freq_your              -0.4809      0.230     -2.093      0.036      -0.931      -0.031\n",
      "word_freq_000                                 2.2078      0.445      4.962      0.000       1.336       3.080\n",
      "word_freq_money                               0.5605      0.191      2.938      0.003       0.187       0.934\n",
      "word_freq_hp                                 -2.1414      0.288     -7.444      0.000      -2.705      -1.578\n",
      "word_freq_hpl                                -1.4390      0.469     -3.067      0.002      -2.359      -0.520\n",
      "word_freq_george                            -12.7754      1.777     -7.189      0.000     -16.259      -9.292\n",
      "word_freq_650                                 0.5676      0.253      2.239      0.025       0.071       1.064\n",
      "word_freq_data                               -0.8550      0.317     -2.698      0.007      -1.476      -0.234\n",
      "word_freq_85                                 -2.5413      1.074     -2.365      0.018      -4.647      -0.435\n",
      "word_freq_technology                          0.9503      0.321      2.962      0.003       0.322       1.579\n",
      "word_freq_pm                                 -1.2787      0.423     -3.024      0.002      -2.108      -0.450\n",
      "word_freq_meeting                            -3.1280      0.894     -3.499      0.000      -4.880      -1.376\n",
      "word_freq_project                            -2.0414      0.576     -3.544      0.000      -3.170      -0.912\n",
      "word_freq_re                                 -0.7778      0.152     -5.115      0.000      -1.076      -0.480\n",
      "word_freq_edu                                -1.6534      0.285     -5.793      0.000      -2.213      -1.094\n",
      "word_freq_conference                         -4.5504      1.702     -2.674      0.008      -7.886      -1.215\n",
      "char_freq_exclamation                         0.2852      0.074      3.830      0.000       0.139       0.431\n",
      "char_freq_semicolon:char_freq_exclamation     3.7388      1.219      3.066      0.002       1.349       6.129\n",
      "char_freq_dollar                              3.0106      0.774      3.890      0.000       1.494       4.527\n",
      "char_freq_exclamation:char_freq_dollar       14.8007      3.707      3.993      0.000       7.535      22.066\n",
      "char_freq_hashtag                             3.5518      0.596      5.961      0.000       2.384       4.720\n",
      "char_freq_semicolon:char_freq_hashtag        -4.7141      1.991     -2.367      0.018      -8.617      -0.811\n",
      "capital_run_length_longest                    0.0124      0.002      7.078      0.000       0.009       0.016\n",
      "capital_run_length_total                      0.0005      0.000      3.136      0.002       0.000       0.001\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(mylogit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cf39f77",
   "metadata": {},
   "source": [
    "The used varaibles in the model are exactly the same as in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a890f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670523\n",
      "         Iterations 4\n",
      "Logit likelihood ratio test p-value: 0.0\n",
      "LinkTest result                  Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 4601\n",
      "Model:                            GLM   Df Residuals:                     4598\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -913.31\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       1826.6\n",
      "Time:                        22:38:29   Pearson chi2:                 2.82e+07\n",
      "No. Iterations:                    11   Pseudo R-squ. (CS):             0.6109\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0254      0.071      0.360      0.719      -0.113       0.164\n",
      "x1             1.0005      0.037     27.086      0.000       0.928       1.073\n",
      "x2            -0.0096      0.014     -0.688      0.492      -0.037       0.018\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "null_logit = sm.Logit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam)))).fit()\n",
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)\n",
    "\n",
    "linktest_result_logit = linktest_logit(mylogit)\n",
    "print(\"LinkTest result\", linktest_result_logit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "558da44f",
   "metadata": {},
   "source": [
    "It seems that yhat is significant and yhat squared is not - this means that now updated model with interactions is correctly specified. The same results were obtained in the initial research."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc2ecfb3",
   "metadata": {},
   "source": [
    "Now let us test the probit model with interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "add39fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.268006\n",
      "         Iterations 13\n",
      "Intercept                                           1.060829e-58\n",
      "word_freq_free                                      2.013689e-27\n",
      "word_freq_order                                     3.707155e-05\n",
      "word_freq_receive                                   5.922157e-01\n",
      "char_freq_hashtag                                   4.317635e-02\n",
      "char_freq_exclamation                               6.030368e-08\n",
      "char_freq_hashtag:char_freq_exclamation             9.817137e-05\n",
      "word_freq_telnet                                    1.765068e-01\n",
      "word_freq_technology                                1.495378e-03\n",
      "word_freq_conference                                4.159086e-03\n",
      "word_freq_edu                                       1.100515e-15\n",
      "word_freq_conference:word_freq_edu                  5.262433e-01\n",
      "word_freq_hp                                        8.853227e-28\n",
      "word_freq_money                                     7.248825e-08\n",
      "word_freq_credit                                    4.063458e-06\n",
      "word_freq_000                                       1.663308e-16\n",
      "char_freq_dollar                                    4.524471e-28\n",
      "word_freq_your                                      1.075997e-10\n",
      "word_freq_email                                     7.861416e-04\n",
      "word_freq_your:word_freq_email                      8.424188e-02\n",
      "word_freq_address                                   1.838695e-02\n",
      "word_freq_your:word_freq_address                    6.701269e-03\n",
      "word_freq_email:word_freq_address                   1.632713e-03\n",
      "word_freq_your:word_freq_email:word_freq_address    1.340764e-04\n",
      "word_freq_people                                    1.774247e-01\n",
      "word_freq_mail                                      6.863608e-03\n",
      "word_freq_george                                    8.802906e-10\n",
      "word_freq_our                                       5.436798e-18\n",
      "word_freq_meeting                                   1.220579e-03\n",
      "word_freq_our:word_freq_meeting                     7.867079e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "formula_interactions = \"spam ~ word_freq_free + word_freq_order + word_freq_receive + char_freq_hashtag * char_freq_exclamation + word_freq_telnet + word_freq_technology + word_freq_conference * word_freq_edu + word_freq_hp + word_freq_money + word_freq_credit + word_freq_000 + char_freq_dollar + word_freq_your * word_freq_email * word_freq_address + word_freq_people + word_freq_mail + word_freq_george + word_freq_our * word_freq_meeting\"\n",
    "\n",
    "myprobit = sm.Probit.from_formula(formula=formula_interactions, data=spam).fit()\n",
    "\n",
    "p = myprobit.pvalues\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2cf4f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_our:word_freq_meeting\n",
      "word_freq_our:word_freq_meeting\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.268018\n",
      "         Iterations 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2524.3003032611086\n",
      "word_freq_receive\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.268049\n",
      "         Iterations 13\n",
      "2522.5914836613906\n",
      "word_freq_conference:word_freq_edu\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.268100\n",
      "         Iterations 13\n",
      "2521.054837918212\n",
      "word_freq_telnet\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.268471\n",
      "         Iterations 13\n",
      "2522.4738070364815\n",
      "word_freq_people\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.268673\n",
      "         Iterations 13\n",
      "2522.325516194447\n",
      "word_freq_your:word_freq_email\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.269005\n",
      "         Iterations 13\n",
      "2523.385000656226\n",
      "char_freq_hashtag\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.269430\n",
      "         Iterations 13\n",
      "2525.290846978696\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        Z = patsy.dmatrix(formula_interactions, data=spam)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        Z = pd.DataFrame(Z, columns=Z.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        Z = Z.drop(worstp, axis=1)\n",
    "        Z_names = ['Intercept'] + list(Z.columns)[1:]\n",
    "        Z.columns = Z_names\n",
    "\n",
    "        myprobit = sm.Probit(spam['spam'], Z).fit()\n",
    "\n",
    "        p = myprobit.pvalues\n",
    "        print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f2b79fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 4601\n",
      "Model:                         Probit   Df Residuals:                     4578\n",
      "Method:                           MLE   Df Model:                           22\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.5982\n",
      "Time:                        22:38:30   Log-Likelihood:                -1239.6\n",
      "converged:                       True   LL-Null:                       -3085.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "====================================================================================================================\n",
      "                                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                           -0.7396      0.046    -16.142      0.000      -0.829      -0.650\n",
      "word_freq_free                                       0.6067      0.056     10.793      0.000       0.497       0.717\n",
      "word_freq_order                                      0.4560      0.110      4.156      0.000       0.241       0.671\n",
      "char_freq_exclamation                                0.1254      0.024      5.322      0.000       0.079       0.172\n",
      "char_freq_hashtag:char_freq_exclamation             16.1087      3.000      5.370      0.000      10.230      21.988\n",
      "word_freq_technology                                 0.4520      0.141      3.216      0.001       0.177       0.727\n",
      "word_freq_conference                                -1.7576      0.554     -3.172      0.002      -2.844      -0.671\n",
      "word_freq_edu                                       -0.8706      0.108     -8.055      0.000      -1.082      -0.659\n",
      "word_freq_hp                                        -1.0880      0.096    -11.377      0.000      -1.275      -0.901\n",
      "word_freq_money                                      0.3329      0.062      5.400      0.000       0.212       0.454\n",
      "word_freq_credit                                     0.8436      0.185      4.568      0.000       0.482       1.206\n",
      "word_freq_000                                        1.6985      0.203      8.374      0.000       1.301       2.096\n",
      "char_freq_dollar                                     2.9527      0.265     11.151      0.000       2.434       3.472\n",
      "word_freq_your                                       0.1546      0.023      6.856      0.000       0.110       0.199\n",
      "word_freq_email                                      0.1901      0.064      2.963      0.003       0.064       0.316\n",
      "word_freq_address                                   -0.1223      0.051     -2.414      0.016      -0.222      -0.023\n",
      "word_freq_your:word_freq_address                     0.1643      0.064      2.579      0.010       0.039       0.289\n",
      "word_freq_email:word_freq_address                    0.6467      0.196      3.293      0.001       0.262       1.032\n",
      "word_freq_your:word_freq_email:word_freq_address    -0.1923      0.044     -4.365      0.000      -0.279      -0.106\n",
      "word_freq_mail                                       0.0972      0.036      2.729      0.006       0.027       0.167\n",
      "word_freq_george                                    -3.1495      0.503     -6.261      0.000      -4.135      -2.164\n",
      "word_freq_our                                        0.3666      0.042      8.758      0.000       0.285       0.449\n",
      "word_freq_meeting                                   -1.4910      0.360     -4.137      0.000      -2.197      -0.785\n",
      "====================================================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.24 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "print(myprobit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0acdff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670523\n",
      "         Iterations 4\n",
      "Probitlikelihood ratio test p-value: 0.0\n",
      "LinkTest result                  Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 4601\n",
      "Model:                            GLM   Df Residuals:                     4598\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       57288.\n",
      "Time:                        22:38:30   Pearson chi2:                 2.80e+18\n",
      "No. Iterations:                    30   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -2.89e+13   1.35e+05  -2.14e+08      0.000   -2.89e+13   -2.89e+13\n",
      "x1          4.013e+13   1.49e+04    2.7e+09      0.000    4.01e+13    4.01e+13\n",
      "x2          7.618e+11    642.395   1.19e+09      0.000    7.62e+11    7.62e+11\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1014: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1014: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "null_probit = sm.Probit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam)))).fit()\n",
    "logit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probitlikelihood ratio test p-value:\", probit_lrtest)\n",
    "\n",
    "linktest_result_probit = linktest_probit(myprobit)\n",
    "print(\"LinkTest result\", linktest_result_probit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d4f9ae4",
   "metadata": {},
   "source": [
    "Bot yhat and yhat squared are significant - the specification of the model is not correct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e005aadc",
   "metadata": {},
   "source": [
    "## As in previous study the Link Test and LR test draw attention to the logit model with interactions that was well specified and significant\n",
    "### Now let us perform other tests for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5548503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness-of-Fit Test:\n",
      "Deviance:  1827.0817098338612\n"
     ]
    }
   ],
   "source": [
    "gof_results = mylogit.deviance\n",
    "print(\"Goodness-of-Fit Test:\")\n",
    "print(\"Deviance: \", gof_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22edd22d",
   "metadata": {},
   "source": [
    "## Hosmer-Lemershow test - for specification\n",
    "## Source: https://stackoverflow.com/questions/40327399/hosmer-lemeshow-goodness-of-fit-test-in-python\n",
    "### Results are in line with our calculations performed originally in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d80f9b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HL test: 0.0\n"
     ]
    }
   ],
   "source": [
    "predictions = mylogit.predict()\n",
    "Y = mylogit.model.endog\n",
    "\n",
    "hl_df = pd.DataFrame({\n",
    "\n",
    "\"P_i\": predictions,\n",
    "\"Outcome\": Y\n",
    "\n",
    "})\n",
    "\n",
    "hl_df[\"decile\"] = pd.qcut(hl_df[\"P_i\"],10)\n",
    "obsevents_1 = hl_df[\"Outcome\"].groupby(hl_df.decile).sum()\n",
    "obsevents_0 = hl_df[\"Outcome\"].groupby(hl_df.decile).count() - obsevents_1\n",
    "expevents_1 = hl_df[\"P_i\"].groupby(hl_df.decile).sum()\n",
    "expevents_0 = hl_df[\"P_i\"].groupby(hl_df.decile).count() - expevents_1\n",
    "hl = (((obsevents_0 - expevents_0)**2)/(expevents_0)).sum() + (((obsevents_1 - expevents_1)**2)/(expevents_1)).sum()\n",
    "pvalue = 1 - chi2.cdf(hl , 10 - 2)\n",
    "\n",
    "print('HL test:', pvalue)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3845d367",
   "metadata": {},
   "source": [
    "## Osius-Rojek Test - the only part of code that could not be reproduced as we were not able to find the function in Python nor write with help of the Internet\n",
    "\n",
    "### The code visible in the bottom were produced by chat gpt based on the description in R function:\n",
    "\n",
    "Osius and Rojek's tests\n",
    "These are based on a power-divergence statistic PD[l] (l=1 for Pearsons test) and the standard deviation (herein, of a binomial distribution) SD. The statistic is:\n",
    "\n",
    "Z[OR] = PD[l] - lbar / SD[l]\n",
    "\n",
    "\n",
    "For logistic regression, it is calculated as:\n",
    "\n",
    "Z[OR] = (chiSq - (n - p)) / (2 * n * SUM 1/n[i])^0.5\n",
    "\n",
    "where RSS is the residual sum-of-squares from a weighted linear regression:\n",
    "\n",
    "(1 - 2 * P[i]) / SD[i] ~ X, weights = SD[i]\n",
    "\n",
    "Here \\bold{X} is the matrix of model predictors.\n",
    "A two-tailed test against a standard normal distribution N ~ (0, 1) should not be significant.\n",
    "\n",
    "Source: Osius G & Rojek D, 1992. Normal goodness-of-fit tests for multinomial models with large degrees of freedom. Journal of the American Statistical Association. 87(420):1145-52. doi: 10.1080/01621459.1992.10476271. Also available at JSTOR at https://www.jstor.org/stable/2290653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6adf25a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic:  202.4603855218882\n",
      "P-value:  0.0\n"
     ]
    }
   ],
   "source": [
    "result = mylogit\n",
    "pred_probs = result.predict()\n",
    "\n",
    "epsilon = 1e-12\n",
    "pred_probs = np.clip(pred_probs, epsilon, 1-epsilon)\n",
    "\n",
    "# Calculate the residuals\n",
    "residuals = (1 - 2 * pred_probs) / np.sqrt(pred_probs * (1 - pred_probs))\n",
    "\n",
    "# Calculate the standard deviation of a binomial distribution (SD)\n",
    "sd = np.sqrt(np.mean(pred_probs * (1 - pred_probs)))\n",
    "\n",
    "# Calculate the residual sum of squares (RSS)\n",
    "rss = np.sum(residuals**2)\n",
    "\n",
    "# Calculate the chi-square value\n",
    "chi_sq = result.llf * -2\n",
    "\n",
    "# Calculate the test statistic Z[OR]\n",
    "n = len(result.model.endog)\n",
    "p = result.df_model\n",
    "test_statistic = (chi_sq - p) / np.sqrt(2 * p)\n",
    "\n",
    "## Value obatined from R - good one\n",
    "#test_statistic = 0.1730284\n",
    "\n",
    "# Calculate the p-value based on a two-tailed test against a standard normal distribution\n",
    "p_value = 1 - stats.norm.cdf(test_statistic)\n",
    "\n",
    "print(\"Test Statistic: \", test_statistic)\n",
    "print(\"P-value: \", p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f3025fa",
   "metadata": {},
   "source": [
    "## McFadden pseudo R-squared"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f5ff822",
   "metadata": {},
   "source": [
    "McFadden's Pseudo-R-squared measures how well our model fits the data by calculating the ratio of the log likelihood for the model and an intercept-only model. The result is presented by subtracting the result from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e9ee9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo R-squared:  0.7038838814093342\n"
     ]
    }
   ],
   "source": [
    "# Pseudo R-squared\n",
    "pseudo_r2 = 1 - (mylogit.llf / mylogit.llnull)\n",
    "print(\"Pseudo R-squared: \", pseudo_r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8028d887",
   "metadata": {},
   "source": [
    "We also calculated the count statistic, which was fully in line with the outcomes produced in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "493ef8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Pseudo R-squared:  0.9280591175831341\n"
     ]
    }
   ],
   "source": [
    "pred_probs = result.predict()\n",
    "y_observed = result.model.endog\n",
    "\n",
    "# Round predicted probabilities to 0 or 1 based on the cutoff of 0.50\n",
    "pred_classes = np.where(pred_probs > 0.50, 1, 0)\n",
    "\n",
    "# Calculate the number of correctly classified cases\n",
    "correctly_classified = np.sum(pred_classes == y_observed)\n",
    "\n",
    "# Calculate the total number of cases\n",
    "total_cases = len(y_observed)\n",
    "\n",
    "# Calculate the count pseudo R-squared\n",
    "count_r2 = correctly_classified / total_cases\n",
    "\n",
    "# Calculate the number of predictors in the model\n",
    "p = result.df_model\n",
    "\n",
    "# Print the pseudo R-squared statistics\n",
    "print(\"Count Pseudo R-squared: \", count_r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06e20c2b",
   "metadata": {},
   "source": [
    "## Marginal effects\n",
    "Source: https://gist.github.com/BioSciEconomist/e5e6cd377ee8ccd565db967e76a58088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "783fadb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0008757521280584903"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# home grown marginal effects function for logit model with 2 variables\n",
    "\n",
    "def mfx(result,mu1,mu2,par):\n",
    "    \"\"\"\n",
    "    result: model object from stats models logistic regression\n",
    "    ex: y ~ b0 + b1*x1 + b2*x2\n",
    "    mu1: mean value for first variable in model\n",
    "    mu2: mean value for 2nd variable in model\n",
    "    par: indicates index from 0 for model parameter you want to convert to a \n",
    "         marginal effect\n",
    "    note: this easily extends to more variables but does not handle predictors\n",
    "          with multiple categories (unless they are dummy coded)\n",
    "    \"\"\"\n",
    "    b0 =  result.params[0]  \n",
    "    b1 =  result.params[1] \n",
    "    b2 =  result.params[2] \n",
    "    XB = mu1*b1 + mu2*b2 + b0 \n",
    "    return (np.exp(XB)/((1+np.exp(XB))**2))*result.params[par]\n",
    "\n",
    "\n",
    "mfx(result,.5,30,1) # home grown function gives almost\n",
    "                    # exact same result as get_margeff() above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7b501022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfx(result, *means, par):\n",
    "    \"\"\"\n",
    "    result: model object from statsmodels logistic regression\n",
    "    means: mean values for each variable in the model (in the same order as the coefficients)\n",
    "    par: index of the model parameter you want to convert to a marginal effect\n",
    "    \"\"\"\n",
    "    b0 = result.params[0]\n",
    "    params = result.params[1:]  # Exclude the intercept\n",
    "    XB = b0 + np.dot(params, means)\n",
    "    exp_XB = np.exp(XB)\n",
    "    marginal_effect = (exp_XB / ((1 + exp_XB) ** 2)) * result.params[par]\n",
    "    return marginal_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0bd3da4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.210805\n",
      "         Iterations 14\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 4601\n",
      "Model:                          Logit   Df Residuals:                     4563\n",
      "Method:                           MLE   Df Model:                           37\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.6856\n",
      "Time:                        22:39:13   Log-Likelihood:                -969.92\n",
      "converged:                       True   LL-Null:                       -3085.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=============================================================================================================\n",
      "                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    -1.2451      0.107    -11.688      0.000      -1.454      -1.036\n",
      "word_freq_make                               -0.4832      0.207     -2.332      0.020      -0.889      -0.077\n",
      "word_freq_address                            -0.1490      0.064     -2.328      0.020      -0.275      -0.024\n",
      "word_freq_our                                 0.5541      0.106      5.217      0.000       0.346       0.762\n",
      "word_freq_address_word_freq_our               0.9072      0.355      2.554      0.011       0.211       1.603\n",
      "word_freq_over                                0.7683      0.246      3.119      0.002       0.285       1.251\n",
      "word_freq_remove                              2.5287      0.347      7.294      0.000       1.849       3.208\n",
      "word_freq_internet                            0.5184      0.152      3.410      0.001       0.220       0.816\n",
      "word_freq_order                               1.6759      0.333      5.038      0.000       1.024       2.328\n",
      "word_freq_free                                1.1187      0.152      7.347      0.000       0.820       1.417\n",
      "word_freq_order_word_freq_free               -1.4575      0.807     -1.807      0.071      -3.039       0.124\n",
      "word_freq_business                            1.2109      0.236      5.120      0.000       0.747       1.674\n",
      "word_freq_order_word_freq_business           -0.9479      0.161     -5.886      0.000      -1.264      -0.632\n",
      "word_freq_you                                 0.0545      0.033      1.628      0.103      -0.011       0.120\n",
      "word_freq_credit                              2.6087      0.633      4.121      0.000       1.368       3.849\n",
      "word_freq_your                                0.2238      0.048      4.699      0.000       0.130       0.317\n",
      "word_freq_credit_word_freq_your              -0.5850      0.249     -2.345      0.019      -1.074      -0.096\n",
      "word_freq_000                                 2.4533      0.481      5.095      0.000       1.510       3.397\n",
      "word_freq_money                               0.6090      0.207      2.945      0.003       0.204       1.014\n",
      "word_freq_hp                                 -2.2200      0.279     -7.958      0.000      -2.767      -1.673\n",
      "word_freq_hpl                                -1.3290      0.462     -2.873      0.004      -2.235      -0.423\n",
      "word_freq_george                             -9.3934      2.108     -4.455      0.000     -13.526      -5.261\n",
      "word_freq_650                                 0.5403      0.246      2.197      0.028       0.058       1.022\n",
      "word_freq_data                               -0.5942      0.258     -2.304      0.021      -1.100      -0.089\n",
      "word_freq_85                                 -1.8168      0.952     -1.908      0.056      -3.683       0.049\n",
      "word_freq_technology                          0.9090      0.319      2.852      0.004       0.284       1.534\n",
      "word_freq_pm                                 -1.3025      0.393     -3.318      0.001      -2.072      -0.533\n",
      "word_freq_meeting                            -2.7385      0.788     -3.474      0.001      -4.283      -1.194\n",
      "word_freq_project                            -2.4918      0.579     -4.300      0.000      -3.628      -1.356\n",
      "word_freq_re                                 -0.8653      0.152     -5.711      0.000      -1.162      -0.568\n",
      "word_freq_edu                                -1.6046      0.271     -5.927      0.000      -2.135      -1.074\n",
      "word_freq_conference                         -2.1460      0.973     -2.206      0.027      -4.053      -0.239\n",
      "char_freq_exclamation                         0.2892      0.072      4.008      0.000       0.148       0.431\n",
      "char_freq_semicolon_char_freq_exclamation     3.7338      1.211      3.082      0.002       1.360       6.108\n",
      "char_freq_dollar                              3.4195      0.712      4.801      0.000       2.024       4.815\n",
      "char_freq_exclamation_char_freq_dollar       16.7776      4.071      4.122      0.000       8.799      24.756\n",
      "char_freq_hashtag                             3.7910      0.534      7.103      0.000       2.745       4.837\n",
      "char_freq_semicolon_char_freq_hashtag        -4.3781      1.981     -2.210      0.027      -8.261      -0.495\n",
      "=============================================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.25 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                   spam\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "=============================================================================================================\n",
      "                                               dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "word_freq_make                               -0.0321      0.014     -2.342      0.019      -0.059      -0.005\n",
      "word_freq_address                            -0.0099      0.004     -2.330      0.020      -0.018      -0.002\n",
      "word_freq_our                                 0.0368      0.007      5.339      0.000       0.023       0.050\n",
      "word_freq_address_word_freq_our               0.0603      0.024      2.559      0.010       0.014       0.106\n",
      "word_freq_over                                0.0510      0.016      3.139      0.002       0.019       0.083\n",
      "word_freq_remove                              0.1680      0.022      7.557      0.000       0.124       0.212\n",
      "word_freq_internet                            0.0344      0.010      3.443      0.001       0.015       0.054\n",
      "word_freq_order                               0.1113      0.022      5.133      0.000       0.069       0.154\n",
      "word_freq_free                                0.0743      0.010      7.642      0.000       0.055       0.093\n",
      "word_freq_order_word_freq_free               -0.0968      0.053     -1.811      0.070      -0.202       0.008\n",
      "word_freq_business                            0.0804      0.015      5.214      0.000       0.050       0.111\n",
      "word_freq_order_word_freq_business           -0.0630      0.010     -6.033      0.000      -0.083      -0.043\n",
      "word_freq_you                                 0.0036      0.002      1.632      0.103      -0.001       0.008\n",
      "word_freq_credit                              0.1733      0.042      4.162      0.000       0.092       0.255\n",
      "word_freq_your                                0.0149      0.003      4.795      0.000       0.009       0.021\n",
      "word_freq_credit_word_freq_your              -0.0389      0.017     -2.353      0.019      -0.071      -0.006\n",
      "word_freq_000                                 0.1630      0.031      5.181      0.000       0.101       0.225\n",
      "word_freq_money                               0.0405      0.014      2.965      0.003       0.014       0.067\n",
      "word_freq_hp                                 -0.1475      0.018     -8.238      0.000      -0.183      -0.112\n",
      "word_freq_hpl                                -0.0883      0.031     -2.884      0.004      -0.148      -0.028\n",
      "word_freq_george                             -0.6240      0.139     -4.501      0.000      -0.896      -0.352\n",
      "word_freq_650                                 0.0359      0.016      2.203      0.028       0.004       0.068\n",
      "word_freq_data                               -0.0395      0.017     -2.308      0.021      -0.073      -0.006\n",
      "word_freq_85                                 -0.1207      0.063     -1.911      0.056      -0.244       0.003\n",
      "word_freq_technology                          0.0604      0.021      2.871      0.004       0.019       0.102\n",
      "word_freq_pm                                 -0.0865      0.026     -3.340      0.001      -0.137      -0.036\n",
      "word_freq_meeting                            -0.1819      0.052     -3.491      0.000      -0.284      -0.080\n",
      "word_freq_project                            -0.1655      0.038     -4.341      0.000      -0.240      -0.091\n",
      "word_freq_re                                 -0.0575      0.010     -5.821      0.000      -0.077      -0.038\n",
      "word_freq_edu                                -0.1066      0.018     -6.038      0.000      -0.141      -0.072\n",
      "word_freq_conference                         -0.1426      0.064     -2.211      0.027      -0.269      -0.016\n",
      "char_freq_exclamation                         0.0192      0.005      4.062      0.000       0.010       0.028\n",
      "char_freq_semicolon_char_freq_exclamation     0.2481      0.080      3.103      0.002       0.091       0.405\n",
      "char_freq_dollar                              0.2272      0.047      4.885      0.000       0.136       0.318\n",
      "char_freq_exclamation_char_freq_dollar        1.1146      0.268      4.154      0.000       0.589       1.640\n",
      "char_freq_hashtag                             0.2519      0.034      7.311      0.000       0.184       0.319\n",
      "char_freq_semicolon_char_freq_hashtag        -0.2909      0.131     -2.215      0.027      -0.548      -0.033\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "X['spam'] = spam['spam']\n",
    "last_column = X.columns[-1]  # Get the name of the last column\n",
    "columns = [last_column] + list(X.columns[:-1])  # Create a new list of column names with the last column at the front\n",
    "X = X[columns]  # Reorder the columns in the DataFrame\n",
    "\n",
    "# Replace the colon with a multiplication sign in the column name\n",
    "X.rename(columns={'char_freq_semicolon:char_freq_exclamation' : 'char_freq_semicolon_char_freq_exclamation'}, inplace=True)\n",
    "X.rename(columns={'char_freq_semicolon:char_freq_hashtag' : 'char_freq_semicolon_char_freq_hashtag'}, inplace=True)\n",
    "X.rename(columns={'word_freq_credit:word_freq_your' : 'word_freq_credit_word_freq_your'}, inplace=True)\n",
    "X.rename(columns={'word_freq_address:word_freq_our' : 'word_freq_address_word_freq_our'}, inplace=True)\n",
    "X.rename(columns={'word_freq_order:word_freq_free' : 'word_freq_order_word_freq_free'}, inplace=True)\n",
    "X.rename(columns={'word_freq_order:word_freq_business' : 'word_freq_order_word_freq_business'}, inplace=True)\n",
    "X.rename(columns={'char_freq_exclamation:char_freq_dollar' : 'char_freq_exclamation_char_freq_dollar'}, inplace=True)\n",
    "\n",
    "epsilon = 1e-8\n",
    "\n",
    "X = X.replace(0, epsilon)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = smf.logit(formula='spam ~ word_freq_make+word_freq_address+word_freq_our+word_freq_address_word_freq_our+word_freq_over+word_freq_remove+word_freq_internet+word_freq_order+word_freq_free+word_freq_order_word_freq_free+word_freq_business+word_freq_order_word_freq_business+word_freq_you+word_freq_credit+word_freq_your+word_freq_credit_word_freq_your+word_freq_000+word_freq_money+word_freq_hp+word_freq_hpl+word_freq_george+word_freq_650+word_freq_data+word_freq_85+word_freq_technology+word_freq_pm+word_freq_meeting+word_freq_project+word_freq_re+word_freq_edu+word_freq_conference+char_freq_exclamation+char_freq_semicolon_char_freq_exclamation+char_freq_dollar+char_freq_exclamation_char_freq_dollar+char_freq_hashtag+char_freq_semicolon_char_freq_hashtag', data=X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# Get marginal effects\n",
    "margeff_overall = model.get_margeff(at='overall')\n",
    "print(margeff_overall.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dfafa57",
   "metadata": {},
   "source": [
    "The marginal effects were a little different due to the fact that we have to exclude 2 variables that could not be used in Python function. However, the results were relatively simillar, with the same sing of coefficients and signifficance of p-values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6588d02",
   "metadata": {},
   "source": [
    "## In summary, we have demonstrated the replicability of our approach through the use of an alternative programming language - the discrepancies were minor and resulted from differences in the implementation of models between R and Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "301b1335",
   "metadata": {},
   "source": [
    "# Spam Detection Project - new data & new keywords\n",
    "\n",
    "### Data preprocessing part"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18f984ae",
   "metadata": {},
   "source": [
    "* Data exploration - let us check how the columns look like and delete unnecessary ones and then move to preprocessing\n",
    "* We dont need the first column 'Unnamed: 0' as it is just an ID\n",
    "* The columns 'label' and 'label_num' depict the same thing, let us only leave 'label_num' that represent spam (1) and non-spam (0) label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0299e62d",
   "metadata": {},
   "source": [
    "Import the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7a486ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\justy\\Desktop\\Info\\Inne\\DSC\\UW\\Semestr IV\\RR\\RR_Project\\Updated Research\\spam.csv\", encoding = \"latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "68214b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"v1\", \"v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b5562a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v1', 'v2'], dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "57893f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename({\"v1\": \"spam\", \"v2\":\"text\"}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ef5f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        spam                    text\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e78effa0",
   "metadata": {},
   "source": [
    "Data preprocessing - we only need to take care of the text column\n",
    "Convert text to lowercase - the iteration is required to go through each mail (it seems that the text was already in lower case but just to make sure let us do it again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e80b8702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point, crazy.. available only in bugis n great world la e buffet... cine there got amore wat...'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    data['text'][i] = data['text'][i].lower()\n",
    "\n",
    "## Check if it worked\n",
    "\n",
    "data['text'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "196f89e2",
   "metadata": {},
   "source": [
    "## Word Frequency\n",
    "\n",
    "The previous analysis was based on word frequencies appearing in the text. In order to obtain the right word frequencies, we have to remove the stopwords as well as conduct lemmantization to obtain the root of the word and reduce the number of unique words. \n",
    "Next, we count the occurence of the top 50 most frequent words, special characters and numbers in each email.\n",
    "\n",
    "We generate the functions with the help of ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0f7e8d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\justy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\justy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Lemmatize each word and remove stop words\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Join the lemmatized words back into a single string\n",
    "    processed_text = ' '.join(lemmatized_words)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ee6d98d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\justy/nltk_data'\n    - 'c:\\\\Users\\\\justy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Users\\\\justy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\justy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\justy\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\justy/nltk_data'\n    - 'c:\\\\Users\\\\justy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Users\\\\justy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\justy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\justy\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14760/774407554.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'processed_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1097\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14760/1466880922.py\u001b[0m in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Lemmatize each word and remove stop words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mlemmatized_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Join the lemmatized words back into a single string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14760/1466880922.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Lemmatize each word and remove stop words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mlemmatized_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Join the lemmatized words back into a single string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \"\"\"\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__reader_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# This is where the magic happens!  Transform ourselves into\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   1174\u001b[0m             )\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprovenances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0momw_prov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# A cache to store the wordnet data of multiple languages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36momw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[0mprovdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m         \u001b[0mprovdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eng\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_omw_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[0mprov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlangfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\justy/nltk_data'\n    - 'c:\\\\Users\\\\justy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Users\\\\justy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\justy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\justy\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "data['processed_text'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94ce9ab9",
   "metadata": {},
   "source": [
    "The words are tokenized excluding the numbers (as random selection of integers were appearing in the top 50). We obtain the 50 most frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d955f576",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'processed_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'processed_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14760/2996162286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Tokenize the text into words while excluding numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mall_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'processed_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3453\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3454\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3455\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'processed_text'"
     ]
    }
   ],
   "source": [
    "# Tokenize the text into words while excluding numbers\n",
    "all_text = data['processed_text'].str.cat(sep=' ')\n",
    "words = nltk.word_tokenize(all_text)\n",
    "words = [word for word in words if word.isalpha()]\n",
    "\n",
    "# Create a frequency distribution of the words\n",
    "freq_dist = FreqDist(words)\n",
    "\n",
    "# Retrieve the most common words\n",
    "num_most_common = 50\n",
    "most_common_words = freq_dist.most_common(num_most_common)\n",
    "\n",
    "# Print the most common words and their frequencies\n",
    "for word, frequency in most_common_words:\n",
    "    print(word, frequency)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef073b64",
   "metadata": {},
   "source": [
    "A list of only the needed words is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb9df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [word for word, count in most_common_words]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d76d8f9",
   "metadata": {},
   "source": [
    "We generate a word frequency matrix for the most common words, as well as adding additional columns for special characters and integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=word_list)\n",
    "X = vectorizer.fit_transform(data[\"processed_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfdd7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "data = pd.concat([data[[\"processed_text\", \"spam\"]], matrix], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in [\"$\", \"€\", \"!\", \"@\", \"?\"]:\n",
    "    pattern = re.escape(char)  # Escape special characters in the regex pattern\n",
    "    data[char] = data[\"processed_text\"].str.count(pattern)\n",
    "\n",
    "data[\"digit_count\"] = data[\"processed_text\"].str.count(r\"\\d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da60a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = data.columns[2:57]\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "data[columns_to_scale] = scaler.fit_transform(data[columns_to_scale])\n",
    "\n",
    "# Display the scaled DataFrame\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r\"\\new_data_new_words.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "599256e8",
   "metadata": {},
   "source": [
    "# Word frequencies from previous analysis\n",
    "\n",
    "We also want to create a word frequency matrix with the words used in the previous analysis. We calculate the frequencies as well as dividing them by the total number of words in the text to match the previous dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old = pd.DataFrame(data[[\"processed_text\", \"spam\"]])\n",
    "\n",
    "words_old = ['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet','order',\n",
    "             'mail', 'receive', 'will', 'people', 'report', 'addresses','free', 'business',\n",
    "             'email', 'you', 'credit', 'your', 'font', '000', 'money', 'hp','hpl','george',\n",
    "             '650', 'lab', 'labs', 'telnet', '857', 'data', '415', '85', 'technology', '1999', \n",
    "             'parts', 'pm', 'direct', 'cs', 'meeting', 'original', 'project', 're', 'edu', 'table',\n",
    "             'conference', ';', '(', '[', '!', '$', '#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381dcaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in words_old:\n",
    "    pattern = re.escape(char)  # Escape special characters in the regex pattern\n",
    "    data_old[char] = data[\"processed_text\"].str.count(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old[\"word_count\"] = data_old[\"processed_text\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old[words_old] = data_old[words_old].div(data_old[\"word_count\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888848",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old.to_csv(r\"\\new_data_old_words.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e861fe72",
   "metadata": {},
   "source": [
    "# The next part of the process was testing the approach on a new dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23adaba6",
   "metadata": {},
   "source": [
    "The analysis will be conducted using word frequencies from the old research as well as a new word list from the new datsaset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc02d7cd",
   "metadata": {},
   "source": [
    "## New Data New Words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f69a7c26",
   "metadata": {},
   "source": [
    "Import and prepare the dataset for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e374216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"Updated Research/new_data_new_words.csv\")\n",
    "spam.dropna(inplace = True)\n",
    "\n",
    "#Renaming character columns to a less error-prone form\n",
    "spam.rename(columns = {'$':'dollar',\n",
    "                       '!': 'exclamation',\n",
    "                      \"#\": \"hashtag\",\n",
    "                       \"(\":\"parenthesis\",\n",
    "                       \"[\": \"brackets\",\n",
    "                       \";\": \"semicolon\",\n",
    "                       \"€\": \"euro\",\n",
    "                       \"@\": \"at\", \n",
    "                       \"?\": \"question\"\n",
    "                      }, inplace = True)\n",
    "\n",
    "#Drop columns not neccessary to the analysis\n",
    "spam.drop(columns=['Unnamed: 0', 'processed_text', 'word_count'], inplace = True)\n",
    "\n",
    "#Rename columns to include word_freq\n",
    "column_names = spam.columns.tolist()\n",
    "new_column_names = ['spam'] + ['word_freq_' + column if column != 'spam' else column for column in column_names[1:]]\n",
    "\n",
    "spam.rename(columns=dict(zip(column_names, new_column_names)), inplace=True)\n",
    "\n",
    "#Convert the dependent variable to a numeric one\n",
    "spam['spam'] = spam['spam'].replace({\n",
    "    'spam': 1,\n",
    "    'ham': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "08b7e500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       spam  word_freq_u  word_freq_call  word_freq_get  word_freq_ur  \\\n",
       "0        0          0.0            0.00            0.0           0.0   \n",
       "1        0          0.0            0.00            0.0           0.0   \n",
       "2        1          0.0            0.00            0.0           0.0   \n",
       "3        0          0.0            0.00            0.0           0.0   \n",
       "4        0          0.0            0.00            0.0           0.0   \n",
       "...    ...          ...             ...            ...           ...   \n",
       "5567     1          0.0            0.08            0.0           0.0   \n",
       "5568     0          0.0            0.00            0.0           0.0   \n",
       "5569     0          0.0            0.00            0.0           0.0   \n",
       "5570     0          0.0            0.00            0.0           0.0   \n",
       "5571     0          0.0            0.00            0.0           0.0   \n",
       "\n",
       "      word_freq_gt  word_freq_lt  word_freq_go  word_freq_free  \\\n",
       "0              0.0           0.0      0.150000        0.000000   \n",
       "1              0.0           0.0      0.000000        0.000000   \n",
       "2              0.0           0.0      0.000000        0.133333   \n",
       "3              0.0           0.0      0.000000        0.000000   \n",
       "4              0.0           0.0      0.333333        0.000000   \n",
       "...            ...           ...           ...             ...   \n",
       "5567           0.0           0.0      0.000000        0.000000   \n",
       "5568           0.0           0.0      0.000000        0.000000   \n",
       "5569           0.0           0.0      0.000000        0.000000   \n",
       "5570           0.0           0.0      0.000000        0.285714   \n",
       "5571           0.0           0.0      0.000000        0.000000   \n",
       "\n",
       "      word_freq_know  ...  word_freq_hi  word_freq_please  word_freq_pls  \\\n",
       "0                0.0  ...           0.0               0.0            0.0   \n",
       "1                0.0  ...           0.0               0.0            0.0   \n",
       "2                0.0  ...           0.0               0.0            0.0   \n",
       "3                0.0  ...           0.0               0.0            0.0   \n",
       "4                0.0  ...           0.0               0.0            0.0   \n",
       "...              ...  ...           ...               ...            ...   \n",
       "5567             0.0  ...           0.0               0.0            0.0   \n",
       "5568             0.0  ...           0.0               0.0            0.0   \n",
       "5569             0.0  ...           0.0               0.0            0.0   \n",
       "5570             0.0  ...           0.0               0.0            0.0   \n",
       "5571             0.0  ...           0.0               0.0            0.0   \n",
       "\n",
       "      word_freq_make  word_freq_dollar  word_freq_euro  word_freq_exclamation  \\\n",
       "0                0.0               0.0             0.0               0.000000   \n",
       "1                0.0               0.0             0.0               0.000000   \n",
       "2                0.0               0.0             0.0               0.000000   \n",
       "3                0.0               0.0             0.0               0.000000   \n",
       "4                0.0               0.0             0.0               0.000000   \n",
       "...              ...               ...             ...                    ...   \n",
       "5567             0.0               0.0             0.0               0.090909   \n",
       "5568             0.0               0.0             0.0               0.000000   \n",
       "5569             0.0               0.0             0.0               0.000000   \n",
       "5570             0.0               0.0             0.0               0.000000   \n",
       "5571             0.0               0.0             0.0               0.000000   \n",
       "\n",
       "      word_freq_at  word_freq_question  word_freq_digit_count  \n",
       "0              0.0            0.000000                      0  \n",
       "1              0.0            0.000000                      0  \n",
       "2              0.0            0.000000                     25  \n",
       "3              0.0            0.000000                      0  \n",
       "4              0.0            0.000000                      0  \n",
       "...            ...                 ...                    ...  \n",
       "5567           0.0            0.000000                     21  \n",
       "5568           0.0            0.083333                      0  \n",
       "5569           0.0            0.083333                      0  \n",
       "5570           0.0            0.000000                      0  \n",
       "5571           0.0            0.000000                      0  \n",
       "\n",
       "[5572 rows x 57 columns]>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.describe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf354f49",
   "metadata": {},
   "source": [
    "Very low variances in independent variables cause errors in the models. We set a treshold for the variances of the columns and keep only the columns that can be included in the analysis. This part was necessary for models to return propper values insted of Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "87311ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam                      0.116111\n",
       "word_freq_call            0.005306\n",
       "word_freq_get             0.003488\n",
       "word_freq_ur              0.003405\n",
       "word_freq_gt              0.007387\n",
       "word_freq_lt              0.009940\n",
       "word_freq_go              0.004034\n",
       "word_freq_free            0.004759\n",
       "word_freq_come            0.003268\n",
       "word_freq_day             0.003685\n",
       "word_freq_time            0.003465\n",
       "word_freq_text            0.004684\n",
       "word_freq_love            0.003443\n",
       "word_freq_send            0.003109\n",
       "word_freq_need            0.003308\n",
       "word_freq_going           0.004255\n",
       "word_freq_sorry           0.004954\n",
       "word_freq_still           0.004305\n",
       "word_freq_take            0.003129\n",
       "word_freq_da              0.004420\n",
       "word_freq_dont            0.003515\n",
       "word_freq_later           0.007791\n",
       "word_freq_exclamation     0.003834\n",
       "word_freq_digit_count    38.995783\n",
       "dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = spam.var()\n",
    "\n",
    "# Set the threshold value\n",
    "threshold = 0.003\n",
    "\n",
    "# Filter columns based on variance threshold\n",
    "filtered_columns = variance[variance >= threshold].index\n",
    "\n",
    "# Create a new DataFrame with selected columns\n",
    "spam = spam[filtered_columns]\n",
    "\n",
    "spam.var()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbc2b2c5",
   "metadata": {},
   "source": [
    "Let us check the distribution of spam and non-spam mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c163db7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spam_count = spam[\"spam\"].value_counts()\n",
    "perc_yes = round(spam_count[1] / len(spam) * 100, 2)\n",
    "perc_no = round(spam_count[0] / len(spam) * 100, 2)\n",
    "\n",
    "plt.bar([\"Non-spam\", \"Spam\"], spam_count, color=[\"#31d64f\", \"#ed3b3b\"])\n",
    "plt.title(\"Number of spam/non-spam mails\")\n",
    "plt.xlabel(\"Type of mail\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend([\"Non-spam\", \"Spam\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ca044cc",
   "metadata": {},
   "source": [
    "## Start from the most general model that contains all explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4fa2fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"spam ~ \" + \" + \".join(spam.columns[1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f30798a6",
   "metadata": {},
   "source": [
    "### Probit model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "18e5d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.084801\n",
      "         Iterations: 35\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5548\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.7848\n",
      "Time:                        22:55:38   Log-Likelihood:                -472.51\n",
      "converged:                      False   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.2321      0.061    -36.431      0.000      -2.352      -2.112\n",
      "word_freq_call           -3.0682      1.010     -3.037      0.002      -5.048      -1.088\n",
      "word_freq_get            -0.1846      0.816     -0.226      0.821      -1.783       1.414\n",
      "word_freq_ur             -1.1577      0.835     -1.387      0.166      -2.794       0.479\n",
      "word_freq_gt            -14.9780   7.81e+05  -1.92e-05      1.000   -1.53e+06    1.53e+06\n",
      "word_freq_lt            -38.8083   6.73e+05  -5.77e-05      1.000   -1.32e+06    1.32e+06\n",
      "word_freq_go             -0.2868      0.757     -0.379      0.705      -1.771       1.197\n",
      "word_freq_free            3.0220      0.419      7.218      0.000       2.201       3.843\n",
      "word_freq_come           -0.5091      1.095     -0.465      0.642      -2.655       1.636\n",
      "word_freq_day            -0.3404      0.797     -0.427      0.669      -1.902       1.222\n",
      "word_freq_time           -0.8513      1.052     -0.809      0.418      -2.914       1.211\n",
      "word_freq_text            1.9207      0.347      5.528      0.000       1.240       2.602\n",
      "word_freq_love           -2.2725      1.616     -1.406      0.160      -5.440       0.895\n",
      "word_freq_send            0.5875      0.701      0.838      0.402      -0.787       1.961\n",
      "word_freq_need           -1.4221      1.381     -1.030      0.303      -4.129       1.285\n",
      "word_freq_going          -1.8651      1.649     -1.131      0.258      -5.097       1.367\n",
      "word_freq_sorry          -3.8238      2.008     -1.904      0.057      -7.760       0.112\n",
      "word_freq_still          -4.7817      3.544     -1.349      0.177     -11.728       2.165\n",
      "word_freq_take           -0.6396      1.117     -0.572      0.567      -2.830       1.550\n",
      "word_freq_da            -48.1537   1.42e+04     -0.003      0.997   -2.79e+04    2.78e+04\n",
      "word_freq_dont           -0.2995      0.984     -0.304      0.761      -2.228       1.629\n",
      "word_freq_later         -61.9383   8.22e+04     -0.001      0.999   -1.61e+05    1.61e+05\n",
      "word_freq_exclamation     2.3871      0.507      4.705      0.000       1.393       3.382\n",
      "word_freq_digit_count     0.3589      0.016     23.073      0.000       0.328       0.389\n",
      "=========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.19 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "myprobit = sm.Probit.from_formula(formula, data=spam).fit()\n",
    "print(myprobit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b061674",
   "metadata": {},
   "source": [
    "### Logit model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f01e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.084299\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                          Logit   Df Residuals:                     5548\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.7861\n",
      "Time:                        22:55:55   Log-Likelihood:                -469.72\n",
      "converged:                      False   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -4.2063      0.143    -29.436      0.000      -4.486      -3.926\n",
      "word_freq_call           -5.9051      2.032     -2.906      0.004      -9.887      -1.923\n",
      "word_freq_get            -0.1263      1.687     -0.075      0.940      -3.432       3.180\n",
      "word_freq_ur             -3.6651      1.709     -2.145      0.032      -7.015      -0.316\n",
      "word_freq_gt            -52.1552   1.26e+05     -0.000      1.000   -2.47e+05    2.47e+05\n",
      "word_freq_lt            -70.7824   1.08e+05     -0.001      0.999   -2.12e+05    2.12e+05\n",
      "word_freq_go             -0.7489      1.788     -0.419      0.675      -4.253       2.755\n",
      "word_freq_free            5.6490      0.834      6.770      0.000       4.013       7.285\n",
      "word_freq_come           -1.6813      2.853     -0.589      0.556      -7.272       3.910\n",
      "word_freq_day            -0.5304      1.635     -0.324      0.746      -3.735       2.674\n",
      "word_freq_time           -2.1441      2.459     -0.872      0.383      -6.963       2.675\n",
      "word_freq_text            3.6967      0.615      6.011      0.000       2.491       4.902\n",
      "word_freq_love           -6.3427      4.199     -1.510      0.131     -14.574       1.888\n",
      "word_freq_send            1.5300      1.418      1.079      0.281      -1.250       4.310\n",
      "word_freq_need           -4.3002      4.018     -1.070      0.285     -12.176       3.576\n",
      "word_freq_going          -6.3393      5.609     -1.130      0.258     -17.333       4.654\n",
      "word_freq_sorry          -6.5950      3.628     -1.818      0.069     -13.705       0.515\n",
      "word_freq_still          -9.5567      7.176     -1.332      0.183     -23.622       4.508\n",
      "word_freq_take           -2.7223      3.339     -0.815      0.415      -9.267       3.822\n",
      "word_freq_da           -100.8663   1725.577     -0.058      0.953   -3482.936    3281.203\n",
      "word_freq_dont           -0.9747      2.531     -0.385      0.700      -5.935       3.986\n",
      "word_freq_later        -149.2632   1.54e+04     -0.010      0.992   -3.04e+04    3.01e+04\n",
      "word_freq_exclamation     4.5261      0.975      4.640      0.000       2.614       6.438\n",
      "word_freq_digit_count     0.7350      0.038     19.591      0.000       0.661       0.809\n",
      "=========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.16 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "mylogit = sm.Logit.from_formula(formula, data=spam).fit()\n",
    "print(mylogit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d3d86db",
   "metadata": {},
   "source": [
    "# Significance test of models\n",
    "\n",
    "Both models p-values are 0, so null hypothesis can be rejected. It means that the model`s coefficients are jointly significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b1c6488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 5\n",
      "Probit likelihood ratio test p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "null_probit = sm.Probit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam)))).fit()\n",
    "probit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probit likelihood ratio test p-value:\", probit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "afe87a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 6\n",
      "Logit likelihood ratio test p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "null_logit = sm.Logit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam)))).fit()\n",
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39dd4f5a",
   "metadata": {},
   "source": [
    "## Stepwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "11906d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_gt\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.084816\n",
      "         Iterations: 35\n",
      "991.194086961016\n",
      "word_freq_da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.085715\n",
      "         Iterations: 35\n",
      "999.2063848097096\n",
      "word_freq_lt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.090247\n",
      "         Iterations: 35\n",
      "1047.7131104852488\n",
      "word_freq_later\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090668\n",
      "         Iterations 10\n",
      "1050.4072904922893\n",
      "word_freq_get\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090669\n",
      "         Iterations 10\n",
      "1048.415447819228\n",
      "word_freq_go\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090671\n",
      "         Iterations 10\n",
      "1046.442614216815\n",
      "word_freq_dont\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090676\n",
      "         Iterations 10\n",
      "1044.491797487975\n",
      "word_freq_day\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090683\n",
      "         Iterations 10\n",
      "1042.5711276093855\n",
      "word_freq_take\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090704\n",
      "         Iterations 10\n",
      "1040.8103242756306\n",
      "word_freq_come\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090728\n",
      "         Iterations 10\n",
      "1039.0676621119137\n",
      "word_freq_send\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090776\n",
      "         Iterations 10\n",
      "1037.6113412700508\n",
      "word_freq_time\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090851\n",
      "         Iterations 10\n",
      "1036.4489011521625\n",
      "word_freq_need\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090967\n",
      "         Iterations 10\n",
      "1035.7413734538893\n",
      "word_freq_going\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091161\n",
      "         Iterations 10\n",
      "1035.8955467500266\n",
      "word_freq_ur\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091284\n",
      "         Iterations 10\n",
      "1035.271195570812\n",
      "word_freq_still\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091649\n",
      "         Iterations 10\n",
      "1037.3409034703454\n",
      "word_freq_love\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091952\n",
      "         Iterations 10\n",
      "1038.7099279546592\n",
      "word_freq_sorry\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092441\n",
      "         Iterations 8\n",
      "1042.162601369397\n"
     ]
    }
   ],
   "source": [
    "p_probit = myprobit.pvalues\n",
    "spam_temp_probit = spam.copy()\n",
    "\n",
    "while any(p_probit > 0.05):\n",
    "    worstp = p_probit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_probit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_probit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    myprobit = sm.Probit.from_formula(formula, data=spam_temp_probit).fit()\n",
    "    p_probit = myprobit.pvalues\n",
    "    print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9320b44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5566\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.7654\n",
      "Time:                        22:56:38   Log-Likelihood:                -515.08\n",
      "converged:                       True   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.3474      0.054    -43.744      0.000      -2.453      -2.242\n",
      "word_freq_call           -2.1198      0.886     -2.394      0.017      -3.855      -0.384\n",
      "word_freq_free            2.8446      0.386      7.376      0.000       2.089       3.601\n",
      "word_freq_text            2.0743      0.334      6.205      0.000       1.419       2.730\n",
      "word_freq_exclamation     2.4478      0.467      5.244      0.000       1.533       3.363\n",
      "word_freq_digit_count     0.3318      0.013     25.563      0.000       0.306       0.357\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(myprobit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "513453b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_gt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1819: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.084316\n",
      "         Iterations: 35\n",
      "985.6201246859478\n",
      "word_freq_da\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.085355\n",
      "         Iterations: 35\n",
      "995.1955540349777\n",
      "word_freq_lt\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.090632\n",
      "         Iterations: 35\n",
      "1051.99881620514\n",
      "word_freq_later\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091062\n",
      "         Iterations 11\n",
      "1054.7944439196922\n",
      "word_freq_get\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091063\n",
      "         Iterations 11\n",
      "1052.801501186288\n",
      "word_freq_day\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091064\n",
      "         Iterations 11\n",
      "1050.8192514721536\n",
      "word_freq_go\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091069\n",
      "         Iterations 11\n",
      "1048.867967823806\n",
      "word_freq_dont\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091080\n",
      "         Iterations 11\n",
      "1046.9987516065275\n",
      "word_freq_come\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091120\n",
      "         Iterations 11\n",
      "1045.4394448720998\n",
      "word_freq_take\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091180\n",
      "         Iterations 11\n",
      "1044.1081245022165\n",
      "word_freq_time\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091261\n",
      "         Iterations 11\n",
      "1043.009973580889\n",
      "word_freq_send\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091332\n",
      "         Iterations 11\n",
      "1041.805252364585\n",
      "word_freq_need\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091494\n",
      "         Iterations 11\n",
      "1041.6097515128067\n",
      "word_freq_going\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091765\n",
      "         Iterations 11\n",
      "1042.6304617980159\n",
      "word_freq_still\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092112\n",
      "         Iterations 10\n",
      "1044.4921206580443\n",
      "word_freq_love\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092502\n",
      "         Iterations 10\n",
      "1046.8384023261974\n",
      "word_freq_sorry\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092979\n",
      "         Iterations 9\n",
      "1050.1593483933716\n",
      "word_freq_ur\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.093262\n",
      "         Iterations 9\n",
      "1051.313098615638\n"
     ]
    }
   ],
   "source": [
    "p_logit = mylogit.pvalues\n",
    "spam_temp_logit = spam.copy()\n",
    "\n",
    "while any(p_logit > 0.05):\n",
    "    worstp = p_logit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_logit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_logit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    mylogit = sm.Logit.from_formula(formula, data=spam_temp_logit).fit()\n",
    "    p_logit = mylogit.pvalues\n",
    "    print(mylogit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c2ab1eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                          Logit   Df Residuals:                     5566\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.7633\n",
      "Time:                        22:57:46   Log-Likelihood:                -519.66\n",
      "converged:                       True   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -4.4589      0.127    -34.977      0.000      -4.709      -4.209\n",
      "word_freq_call           -4.0560      1.688     -2.403      0.016      -7.364      -0.748\n",
      "word_freq_free            5.3216      0.729      7.303      0.000       3.893       6.750\n",
      "word_freq_text            4.0642      0.589      6.903      0.000       2.910       5.218\n",
      "word_freq_exclamation     4.6051      0.859      5.362      0.000       2.922       6.288\n",
      "word_freq_digit_count     0.6596      0.030     22.189      0.000       0.601       0.718\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(mylogit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63e3e9ea",
   "metadata": {},
   "source": [
    "It seems that the stepwise regression deletes almost all new variables as their signifficance is not passing the 5% threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa614327",
   "metadata": {},
   "source": [
    "## Link test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b1719c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linktest_probit(model):\n",
    "    \"\"\"\n",
    "    Function to perform linktest on a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "    - model: logistic regression model object\n",
    "    \n",
    "    Returns:\n",
    "    - aux_reg: auxiliary regression model object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the data\n",
    "    y = model.model.endog\n",
    "    pred = model.predict()\n",
    "    pred = np.clip(pred, 1e-12, 1 - 1e-12)\n",
    "    yhat = np.log(pred/(1-pred))\n",
    "    yhat2 = yhat**2\n",
    "\n",
    "    # Add constant column to predictor variables\n",
    "    X = np.column_stack((np.ones_like(y), yhat, yhat2))\n",
    "\n",
    "    # Remove rows with missing or infinite values\n",
    "    valid_idx = np.isfinite(X).all(axis=1)\n",
    "    X = X[valid_idx]\n",
    "    y = y[valid_idx]\n",
    "\n",
    "    # Fit the binomial regression model\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial(link=sm.genmod.families.links.probit()))\n",
    "    result = model.fit()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def linktest_logit(model):\n",
    "    \"\"\"\n",
    "    Function to perform linktest on a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "    - model: logistic regression model object\n",
    "    \n",
    "    Returns:\n",
    "    - aux_reg: auxiliary regression model object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the data\n",
    "    y = model.model.endog\n",
    "    pred = model.predict()\n",
    "    pred = np.clip(pred, 1e-12, 1 - 1e-12)\n",
    "    yhat = np.log(pred/(1-pred))\n",
    "    yhat2 = yhat**2\n",
    "\n",
    "    # Add constant column to predictor variables\n",
    "    X = np.column_stack((np.ones_like(y), yhat, yhat2))\n",
    "\n",
    "    # Remove rows with missing or infinite values\n",
    "    valid_idx = np.isfinite(X).all(axis=1)\n",
    "    X = X[valid_idx]\n",
    "    y = y[valid_idx]\n",
    "\n",
    "    # Fit the binomial regression model\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial(link=sm.genmod.families.links.logit()))\n",
    "    result = model.fit()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aed8d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -498.75\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       997.50\n",
      "Time:                        22:58:46   Pearson chi2:                 6.00e+04\n",
      "No. Iterations:                    10   Pseudo R-squ. (CS):             0.4561\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1035      0.068      1.533      0.125      -0.029       0.236\n",
      "x1             0.4932      0.017     28.757      0.000       0.460       0.527\n",
      "x2            -0.0149      0.001    -16.346      0.000      -0.017      -0.013\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Linktest for probit model - after stepwise regression\n",
    "linktest_result_probit = linktest_probit(myprobit)\n",
    "print(linktest_result_probit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c298020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -506.88\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       1013.8\n",
      "Time:                        22:58:49   Pearson chi2:                 4.31e+03\n",
      "No. Iterations:                     8   Pseudo R-squ. (CS):             0.4545\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2302      0.131      1.752      0.080      -0.027       0.488\n",
      "x1             0.9447      0.036     26.424      0.000       0.875       1.015\n",
      "x2            -0.0339      0.003    -11.359      0.000      -0.040      -0.028\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Linktest for logit model - after stepwise regression\n",
    "linktest_result_logit = linktest_logit(mylogit)\n",
    "print(linktest_result_logit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e56c8ca0",
   "metadata": {},
   "source": [
    "For both models the yhat and  yhat squared were significant - it indicates that the specification is wrong"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e119155",
   "metadata": {},
   "source": [
    "### Interaction terms\n",
    "Adding interaction terms and deleting insignificant ones for probit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "43dc870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.339735\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "formula_interactions = \"spam ~  word_freq_free * word_freq_exclamation  + word_freq_send \"\n",
    "myprobit = sm.Probit.from_formula(formula_interactions, data=spam).fit()\n",
    "p_probit = myprobit.pvalues\n",
    "spam_temp_probit = spam.copy()\n",
    "\n",
    "while any(p_probit > 0.05):\n",
    "    worstp = p_probit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_probit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = formula_interactions\n",
    "    \n",
    "    for column in spam_temp_probit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    myprobit = sm.Probit.from_formula(formula, data=spam_temp_probit).fit()\n",
    "    p_probit = myprobit.pvalues\n",
    "    print(myprobit.aic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "32f1a33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5567\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.1378\n",
      "Time:                        23:01:07   Log-Likelihood:                -1893.0\n",
      "converged:                       True   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.186e-129\n",
      "========================================================================================================\n",
      "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Intercept                               -1.3616      0.026    -52.848      0.000      -1.412      -1.311\n",
      "word_freq_free                           3.0849      0.252     12.240      0.000       2.591       3.579\n",
      "word_freq_exclamation                    4.6667      0.290     16.104      0.000       4.099       5.235\n",
      "word_freq_free:word_freq_exclamation    80.1031     14.484      5.530      0.000      51.715     108.491\n",
      "word_freq_send                           1.1674      0.349      3.341      0.001       0.483       1.852\n",
      "========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(myprobit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8bab63f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.340333\n",
      "         Iterations 9\n"
     ]
    }
   ],
   "source": [
    "mylogit = sm.Logit.from_formula(formula_interactions, data=spam).fit()\n",
    "p_logit = mylogit.pvalues\n",
    "spam_temp_probit = spam.copy()\n",
    "\n",
    "while any(p_logit > 0.05):\n",
    "    worstp = p_logit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_logit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = formula_interactions\n",
    "    \n",
    "    for column in spam_temp_logit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    mylogit = sm.Logit.from_formula(formula, data=spam_temp_logit).fit()\n",
    "    p_logit = mylogit.pvalues\n",
    "    print(mylogit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fd219e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                          Logit   Df Residuals:                     5567\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.1363\n",
      "Time:                        23:01:21   Log-Likelihood:                -1896.3\n",
      "converged:                       True   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.290e-128\n",
      "========================================================================================================\n",
      "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Intercept                               -2.3404      0.051    -46.226      0.000      -2.440      -2.241\n",
      "word_freq_free                           6.1390      0.594     10.332      0.000       4.974       7.304\n",
      "word_freq_exclamation                    8.8380      0.585     15.116      0.000       7.692       9.984\n",
      "word_freq_free:word_freq_exclamation   136.6312     30.253      4.516      0.000      77.337     195.925\n",
      "word_freq_send                           1.9587      0.590      3.321      0.001       0.803       3.114\n",
      "========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(mylogit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d2312e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probit likelihood ratio test p-value: 1.2652102247811568e-133\n"
     ]
    }
   ],
   "source": [
    "probit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probit likelihood ratio test p-value:\", probit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6efd3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit likelihood ratio test p-value: 3.567628329112654e-132\n"
     ]
    }
   ],
   "source": [
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ebf09555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1866.7\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3733.3\n",
      "Time:                        23:00:34   Pearson chi2:                 7.95e+03\n",
      "No. Iterations:                     9   Pseudo R-squ. (CS):             0.1114\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0758      0.064      1.180      0.238      -0.050       0.202\n",
      "x1             0.5770      0.028     20.431      0.000       0.522       0.632\n",
      "x2            -0.0203      0.001    -14.468      0.000      -0.023      -0.018\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Linktest for probit model - after stepwise regression\n",
    "linktest_result_probit = linktest_probit(myprobit)\n",
    "print(linktest_result_probit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a8cde6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1874.7\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3749.5\n",
      "Time:                        23:00:37   Pearson chi2:                 5.55e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.1088\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1382      0.104      1.324      0.185      -0.066       0.343\n",
      "x1             0.9912      0.048     20.616      0.000       0.897       1.085\n",
      "x2            -0.0375      0.003    -11.095      0.000      -0.044      -0.031\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Linktest for logit model - after stepwise regression\n",
    "linktest_result_logit = linktest_logit(mylogit)\n",
    "print(linktest_result_logit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d07ec3e",
   "metadata": {},
   "source": [
    "It seems that including the set of words that we have chosen, even with interaction terms are not sufficient enough to pass the specification Link test. Most probably the set of words should be updated with different keywords. However, let us continue with the steps that were executed for the initial project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1841771c",
   "metadata": {},
   "source": [
    "### Other tests (goodness of fit & specification) for new data and new words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c2aba1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                               0.000000e+00\n",
      "word_freq_free                          1.427736e-26\n",
      "word_freq_exclamation                   1.769530e-50\n",
      "word_freq_free:word_freq_exclamation    1.710706e-05\n",
      "word_freq_send                          1.309985e-03\n",
      "word_freq_get                           3.225381e-02\n",
      "word_freq_ur                            9.726582e-05\n",
      "word_freq_get:word_freq_ur              8.443402e-01\n",
      "word_freq_still                         7.665286e-03\n",
      "word_freq_sorry                         1.253296e-03\n",
      "dtype: float64\n",
      "Intercept                               0.000000e+00\n",
      "word_freq_free                          1.892276e-34\n",
      "word_freq_exclamation                   2.398555e-58\n",
      "word_freq_free:word_freq_exclamation    3.194177e-08\n",
      "word_freq_send                          8.336926e-04\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "formula_interactions = \"spam ~  word_freq_free * word_freq_exclamation  + word_freq_send + word_freq_get*word_freq_ur + word_freq_still + word_freq_sorry\"\n",
    "\n",
    "mylogit = sm.formula.glm(formula_interactions, data=spam, family=sm.families.Binomial(sm.genmod.families.links.logit())).fit()\n",
    "\n",
    "p = mylogit.pvalues\n",
    "print(p)\n",
    "\n",
    "mylogit = sm.formula.glm(formula_interactions, data=spam, family=sm.families.Binomial(sm.genmod.families.links.probit())).fit()\n",
    "\n",
    "p = myprobit.pvalues\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a2ccf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        X = patsy.dmatrix(formula_interactions, data=spam)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        X = X.drop(worstp, axis=1)\n",
    "        X_names = ['Intercept'] + list(X.columns)[1:]\n",
    "        X.columns = X_names\n",
    "\n",
    "        myprobit = sm.Probit(spam['spam'], X).fit()\n",
    "\n",
    "        print(myprobit.summary())\n",
    "        p = myprobit.pvalues\n",
    "        print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f044ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        X = patsy.dmatrix(formula_interactions, data=spam)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        X = X.drop(worstp, axis=1)\n",
    "        X_names = ['Intercept'] + list(X.columns)[1:]\n",
    "        X.columns = X_names\n",
    "\n",
    "        mylogit = sm.GLM(spam['spam'], X, family=sm.families.Binomial(sm.families.links.logit())).fit()\n",
    "\n",
    "        print(mylogit.summary())\n",
    "        p = mylogit.pvalues\n",
    "        print(mylogit.aic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f35c2695",
   "metadata": {},
   "source": [
    "### Goodnes of fit tests\n",
    "\n",
    "Based on the Pseud R squared it seems that the model with new words right now is very poor quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "694ae980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit | Goodness-of-Fit Test:\n",
      "Logit | Deviance:  3724.4546891739965\n"
     ]
    }
   ],
   "source": [
    "gof_results = mylogit.deviance\n",
    "print(\"Logit | Goodness-of-Fit Test:\")\n",
    "print(\"Logit | Deviance: \", gof_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c4194f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit | Pseudo R-squared:  0.15182947635330224\n",
      "Probit | Pseudo R-squared:  0.13781243162991286\n"
     ]
    }
   ],
   "source": [
    "pseudo_r2 = 1 - (mylogit.llf / mylogit.llnull)\n",
    "print(\"Logit | Pseudo R-squared: \", pseudo_r2)\n",
    "\n",
    "pseudo_r2 = 1 - (myprobit.llf / myprobit.llnull)\n",
    "print(\"Probit | Pseudo R-squared: \", pseudo_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "626d0668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Pseudo R-squared:  0.8752692031586504\n"
     ]
    }
   ],
   "source": [
    "pred_probs = result.predict()\n",
    "y_observed = result.model.endog\n",
    "\n",
    "# Round predicted probabilities to 0 or 1 based on the cutoff of 0.50\n",
    "pred_classes = np.where(pred_probs > 0.50, 1, 0)\n",
    "\n",
    "# Calculate the number of correctly classified cases\n",
    "correctly_classified = np.sum(pred_classes == y_observed)\n",
    "\n",
    "# Calculate the total number of cases\n",
    "total_cases = len(y_observed)\n",
    "\n",
    "# Calculate the count pseudo R-squared\n",
    "count_r2 = correctly_classified / total_cases\n",
    "\n",
    "# Calculate the number of predictors in the model\n",
    "p = result.df_model\n",
    "\n",
    "# Print the pseudo R-squared statistics\n",
    "print(\"Count Pseudo R-squared: \", count_r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c82b698",
   "metadata": {},
   "source": [
    "### The analysis using the new word list was limited due to low variances in word frequencies and more varied text corpus'.The probit and logit models performed much worse even after applying the general to specific framework. The replication of our approach on a new dataset was more challenging – the key to improving results was updating the list of words, which confirms our initial observation that language in both real conversations and spam e-mail evolves."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8003849",
   "metadata": {},
   "source": [
    "# New Data Old Words\n",
    "\n",
    "In this part of the analysis we will try to recreate the previous research on the new data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ca39b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_previous_words = pd.read_csv(\"new_data_old_words.csv\")\n",
    "spam_previous_words.dropna(inplace = True)\n",
    "\n",
    "#Renaming character columns to a less error-prone form\n",
    "spam_previous_words.rename(columns = {'$':'dollar',\n",
    "                       '!': 'exclamation',\n",
    "                      \"#\": \"hashtag\",\n",
    "                       \"(\":\"parenthesis\",\n",
    "                       \"[\": \"brackets\",\n",
    "                       \";\": \"semicolon\",\n",
    "                       \"€\": \"euro\",\n",
    "                       \"@\": \"at\", \n",
    "                       \"?\": \"question\"\n",
    "                      }, inplace = True)\n",
    "\n",
    "#Drop columns not neccessary to the analysis\n",
    "spam_previous_words.drop(columns=['Unnamed: 0', 'processed_text', 'word_count'], inplace = True)\n",
    "\n",
    "#Rename columns to include word_freq\n",
    "column_names = spam_previous_words.columns.tolist()\n",
    "new_column_names = ['spam'] + ['word_freq_' + column if column != 'spam' else column for column in column_names[1:]]\n",
    "\n",
    "spam_previous_words.rename(columns=dict(zip(column_names, new_column_names)), inplace=True)\n",
    "\n",
    "#Convert the dependent variable to a numeric one\n",
    "spam_previous_words['spam'] = spam_previous_words['spam'].replace({\n",
    "    'spam': 1,\n",
    "    'ham': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a7c13e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       spam  word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0        0             0.0                0.0           0.00           0.0   \n",
       "1        0             0.0                0.0           0.00           0.0   \n",
       "2        1             0.0                0.0           0.00           0.0   \n",
       "3        0             0.0                0.0           0.00           0.0   \n",
       "4        0             0.0                0.0           0.00           0.0   \n",
       "...    ...             ...                ...            ...           ...   \n",
       "5567     1             0.0                0.0           0.04           0.0   \n",
       "5568     0             0.0                0.0           0.00           0.0   \n",
       "5569     0             0.0                0.0           0.00           0.0   \n",
       "5570     0             0.0                0.0           0.00           0.0   \n",
       "5571     0             0.0                0.0           0.00           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0               0.0        0.000000               0.0                 0.0   \n",
       "1               0.0        0.000000               0.0                 0.0   \n",
       "2               0.0        0.033333               0.0                 0.0   \n",
       "3               0.0        0.000000               0.0                 0.0   \n",
       "4               0.0        0.000000               0.0                 0.0   \n",
       "...             ...             ...               ...                 ...   \n",
       "5567            0.0        0.000000               0.0                 0.0   \n",
       "5568            0.0        0.000000               0.0                 0.0   \n",
       "5569            0.0        0.000000               0.0                 0.0   \n",
       "5570            0.0        0.000000               0.0                 0.0   \n",
       "5571            0.0        0.000000               0.0                 0.0   \n",
       "\n",
       "      word_freq_order  ...  word_freq_re  word_freq_edu  word_freq_table  \\\n",
       "0                 0.0  ...      0.100000            0.0              0.0   \n",
       "1                 0.0  ...      0.000000            0.0              0.0   \n",
       "2                 0.0  ...      0.066667            0.0              0.0   \n",
       "3                 0.0  ...      0.090909            0.0              0.0   \n",
       "4                 0.0  ...      0.000000            0.0              0.0   \n",
       "...               ...  ...           ...            ...              ...   \n",
       "5567              0.0  ...      0.000000            0.0              0.0   \n",
       "5568              0.0  ...      0.000000            0.0              0.0   \n",
       "5569              0.0  ...      0.000000            0.0              0.0   \n",
       "5570              0.0  ...      0.142857            0.0              0.0   \n",
       "5571              0.0  ...      0.000000            0.0              0.0   \n",
       "\n",
       "      word_freq_conference  word_freq_semicolon  word_freq_parenthesis  \\\n",
       "0                      0.0                  0.0               0.000000   \n",
       "1                      0.0                  0.0               0.000000   \n",
       "2                      0.0                  0.0               0.033333   \n",
       "3                      0.0                  0.0               0.000000   \n",
       "4                      0.0                  0.0               0.000000   \n",
       "...                    ...                  ...                    ...   \n",
       "5567                   0.0                  0.0               0.000000   \n",
       "5568                   0.0                  0.0               0.000000   \n",
       "5569                   0.0                  0.0               0.000000   \n",
       "5570                   0.0                  0.0               0.000000   \n",
       "5571                   0.0                  0.0               0.000000   \n",
       "\n",
       "      word_freq_brackets  word_freq_exclamation  word_freq_dollar  \\\n",
       "0                    0.0                   0.00               0.0   \n",
       "1                    0.0                   0.00               0.0   \n",
       "2                    0.0                   0.00               0.0   \n",
       "3                    0.0                   0.00               0.0   \n",
       "4                    0.0                   0.00               0.0   \n",
       "...                  ...                    ...               ...   \n",
       "5567                 0.0                   0.04               0.0   \n",
       "5568                 0.0                   0.00               0.0   \n",
       "5569                 0.0                   0.00               0.0   \n",
       "5570                 0.0                   0.00               0.0   \n",
       "5571                 0.0                   0.00               0.0   \n",
       "\n",
       "      word_freq_hashtag  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "...                 ...  \n",
       "5567                0.0  \n",
       "5568                0.0  \n",
       "5569                0.0  \n",
       "5570                0.0  \n",
       "5571                0.0  \n",
       "\n",
       "[5572 rows x 55 columns]>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_previous_words.describe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72335d16",
   "metadata": {},
   "source": [
    "We once again remove the columns with very low variances to ensure that the selected models run smoothly. We decrease the treshold as the previously used words are less frequently found in the new dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ab3f727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam                     0.116111\n",
       "word_freq_make           0.000206\n",
       "word_freq_all            0.002106\n",
       "word_freq_our            0.000249\n",
       "word_freq_free           0.000335\n",
       "word_freq_meeting        0.000171\n",
       "word_freq_re             0.005786\n",
       "word_freq_edu            0.000193\n",
       "word_freq_semicolon      0.000912\n",
       "word_freq_exclamation    0.002293\n",
       "word_freq_hashtag        0.000174\n",
       "dtype: float64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = spam_previous_words.var()\n",
    "\n",
    "# Set the threshold value\n",
    "threshold = 0.00017\n",
    "\n",
    "# Filter columns based on variance threshold\n",
    "filtered_columns = variance[variance >= threshold].index\n",
    "\n",
    "# Create a new DataFrame with selected columns\n",
    "spam_previous_words = spam_previous_words[filtered_columns]\n",
    "\n",
    "spam_previous_words.var()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d970976d",
   "metadata": {},
   "source": [
    "## Start from the most general model that contains all explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "125e3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"spam ~ \" + \" + \".join(spam_previous_words.columns[1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1ab2444",
   "metadata": {},
   "source": [
    "### Probit model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f6a8c10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.346699\n",
      "         Iterations: 35\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5561\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.1201\n",
      "Time:                        23:27:23   Log-Likelihood:                -1931.8\n",
      "converged:                      False   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                5.689e-107\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.3365      0.030    -44.156      0.000      -1.396      -1.277\n",
      "word_freq_make           -2.8613      2.004     -1.428      0.153      -6.788       1.066\n",
      "word_freq_all             3.4102      0.418      8.157      0.000       2.591       4.230\n",
      "word_freq_our            -1.5310      1.753     -0.873      0.383      -4.967       1.905\n",
      "word_freq_free           13.3079      0.943     14.117      0.000      11.460      15.156\n",
      "word_freq_meeting       -63.2651    258.498     -0.245      0.807    -569.913     443.382\n",
      "word_freq_re              0.6952      0.293      2.370      0.018       0.120       1.270\n",
      "word_freq_edu             0.0336      1.786      0.019      0.985      -3.467       3.534\n",
      "word_freq_semicolon     -15.5432      3.426     -4.536      0.000     -22.259      -8.828\n",
      "word_freq_exclamation     3.9516      0.382     10.334      0.000       3.202       4.701\n",
      "word_freq_hashtag         8.6956      5.876      1.480      0.139      -2.821      20.212\n",
      "=========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "myprobit = sm.Probit.from_formula(formula, data=spam_previous_words).fit()\n",
    "print(myprobit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5904585",
   "metadata": {},
   "source": [
    "### Logit model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ace24a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.345718\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                          Logit   Df Residuals:                     5561\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.1226\n",
      "Time:                        23:27:26   Log-Likelihood:                -1926.3\n",
      "converged:                      False   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.607e-109\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.2665      0.057    -39.851      0.000      -2.378      -2.155\n",
      "word_freq_make           -5.0935      3.852     -1.322      0.186     -12.643       2.456\n",
      "word_freq_all             5.9660      0.719      8.301      0.000       4.557       7.375\n",
      "word_freq_our            -3.1607      3.407     -0.928      0.353      -9.837       3.516\n",
      "word_freq_free           30.6567      2.325     13.185      0.000      26.100      35.214\n",
      "word_freq_meeting      -355.2737   1.48e+04     -0.024      0.981   -2.94e+04    2.86e+04\n",
      "word_freq_re              1.0368      0.521      1.988      0.047       0.015       2.059\n",
      "word_freq_edu             0.1133      3.141      0.036      0.971      -6.043       6.269\n",
      "word_freq_semicolon     -39.6419      9.498     -4.174      0.000     -58.258     -21.026\n",
      "word_freq_exclamation     6.4094      0.660      9.710      0.000       5.116       7.703\n",
      "word_freq_hashtag        22.0823     11.556      1.911      0.056      -0.566      44.731\n",
      "=========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "mylogit = sm.Logit.from_formula(formula, data=spam_previous_words).fit()\n",
    "print(mylogit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8616469",
   "metadata": {},
   "source": [
    "# Significance test of models\n",
    "\n",
    "Both models p-values are below the 0.05 treshold, so the null hypothesis can be rejected. It means that the model`s coefficients are jointly significant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b289a9b0",
   "metadata": {},
   "source": [
    "### Stepwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0faf5420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 5\n",
      "Probit likelihood ratio test p-value: 9.630820582495782e-117\n"
     ]
    }
   ],
   "source": [
    "null_probit = sm.Probit(spam_previous_words[\"spam\"], sm.add_constant(pd.Series([1] * len(spam_previous_words)))).fit()\n",
    "probit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probit likelihood ratio test p-value:\", probit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "80487f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 5\n",
      "Logit likelihood ratio test p-value: 4.026157970991869e-119\n"
     ]
    }
   ],
   "source": [
    "null_logit = sm.Probit(spam_previous_words[\"spam\"], sm.add_constant(pd.Series([1] * len(spam_previous_words)))).fit()\n",
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2e4c97ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_edu\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.346699\n",
      "         Iterations: 35\n",
      "3883.611568279135\n",
      "word_freq_meeting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347861\n",
      "         Iterations 9\n",
      "3894.5620657017016\n",
      "word_freq_our\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347931\n",
      "         Iterations 9\n",
      "3893.347126774049\n",
      "word_freq_make\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.348152\n",
      "         Iterations 9\n",
      "3893.801264632376\n",
      "word_freq_hashtag\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.348337\n",
      "         Iterations 9\n",
      "3893.8690589270027\n"
     ]
    }
   ],
   "source": [
    "p_probit = myprobit.pvalues\n",
    "spam_temp_probit = spam_previous_words.copy()\n",
    "\n",
    "while any(p_probit > 0.05):\n",
    "    worstp = p_probit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_probit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_probit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    myprobit = sm.Probit.from_formula(formula, data=spam_temp_probit).fit()\n",
    "    p_probit = myprobit.pvalues\n",
    "    print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "413648c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5566\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.1160\n",
      "Time:                        23:28:03   Log-Likelihood:                -1940.9\n",
      "converged:                       True   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.873e-108\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.3462      0.030    -44.882      0.000      -1.405      -1.287\n",
      "word_freq_all             3.2810      0.415      7.904      0.000       2.467       4.095\n",
      "word_freq_free           13.4103      0.942     14.231      0.000      11.563      15.257\n",
      "word_freq_re              0.6922      0.293      2.361      0.018       0.118       1.267\n",
      "word_freq_semicolon     -12.9549      3.041     -4.260      0.000     -18.915      -6.995\n",
      "word_freq_exclamation     3.9721      0.382     10.408      0.000       3.224       4.720\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(myprobit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "669a9345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_meeting\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.346883\n",
      "         Iterations 10\n",
      "3885.6663210969095\n",
      "word_freq_edu\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.346883\n",
      "         Iterations 10\n",
      "3883.668076162318\n",
      "word_freq_our\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.346967\n",
      "         Iterations 10\n",
      "3882.598757849927\n",
      "word_freq_make\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347171\n",
      "         Iterations 10\n",
      "3882.8707237137123\n",
      "word_freq_hashtag\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347500\n",
      "         Iterations 10\n",
      "3884.5432016359223\n"
     ]
    }
   ],
   "source": [
    "p_logit = mylogit.pvalues\n",
    "spam_temp_logit = spam_previous_words.copy()\n",
    "\n",
    "while any(p_logit > 0.05):\n",
    "    worstp = p_logit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_logit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_logit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    mylogit = sm.Logit.from_formula(formula, data=spam_temp_logit).fit()\n",
    "    p_logit = mylogit.pvalues\n",
    "    print(mylogit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "30bdc89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                          Logit   Df Residuals:                     5566\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.1181\n",
      "Time:                        23:28:17   Log-Likelihood:                -1936.3\n",
      "converged:                       True   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.635e-110\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.2850      0.056    -40.489      0.000      -2.396      -2.174\n",
      "word_freq_all             5.7610      0.712      8.092      0.000       4.366       7.156\n",
      "word_freq_free           30.7868      2.332     13.203      0.000      26.216      35.357\n",
      "word_freq_re              1.0500      0.521      2.015      0.044       0.029       2.071\n",
      "word_freq_semicolon     -32.1995      8.798     -3.660      0.000     -49.443     -14.956\n",
      "word_freq_exclamation     6.4342      0.658      9.772      0.000       5.144       7.725\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(mylogit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ce166104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1820.1\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3640.2\n",
      "Time:                        23:26:28   Pearson chi2:                 7.15e+06\n",
      "No. Iterations:                     8   Pseudo R-squ. (CS):             0.1261\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.6124      0.099      6.195      0.000       0.419       0.806\n",
      "x1             0.7290      0.059     12.341      0.000       0.613       0.845\n",
      "x2            -0.2962      0.027    -10.961      0.000      -0.349      -0.243\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Linktest for probit model - after stepwise regression\n",
    "linktest_result_logit = linktest_logit(mylogit)\n",
    "print(linktest_result_logit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ff1c1f2",
   "metadata": {},
   "source": [
    "### Interaction terms\n",
    "---\n",
    "We include the interaction terms from the previous research. The variables that were discarded due to low variances are excluded from the interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c6d6576c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spam', 'word_freq_make', 'word_freq_all', 'word_freq_our',\n",
       "       'word_freq_free', 'word_freq_meeting', 'word_freq_re', 'word_freq_edu',\n",
       "       'word_freq_semicolon', 'word_freq_exclamation', 'word_freq_hashtag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_previous_words.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c6a4587",
   "metadata": {},
   "source": [
    "### Logit\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8a6d1be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                                                      0.000000e+00\n",
      "word_freq_make                                                 2.380242e-01\n",
      "word_freq_our                                                  3.489793e-01\n",
      "word_freq_make:word_freq_our                                   9.999865e-01\n",
      "word_freq_free                                                 4.468356e-47\n",
      "word_freq_meeting                                              9.997683e-01\n",
      "word_freq_edu                                                  9.950311e-01\n",
      "word_freq_semicolon                                            2.518382e-02\n",
      "word_freq_exclamation                                          2.167942e-20\n",
      "word_freq_semicolon:word_freq_exclamation                      9.999221e-01\n",
      "word_freq_hashtag                                              3.630297e-01\n",
      "word_freq_semicolon:word_freq_hashtag                          9.987517e-01\n",
      "word_freq_exclamation:word_freq_hashtag                        9.999173e-01\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag    9.999374e-01\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:187: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    }
   ],
   "source": [
    "formula_interactions = \"spam ~ word_freq_make * word_freq_our  +  word_freq_free + word_freq_meeting  + word_freq_edu +  word_freq_semicolon * word_freq_exclamation * word_freq_hashtag\"\n",
    "\n",
    "mylogit = sm.formula.glm(formula_interactions, data=spam_previous_words, family=sm.families.Binomial(sm.genmod.families.links.logit())).fit()\n",
    "\n",
    "p = mylogit.pvalues\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1ce506e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make:word_freq_our\n",
      "word_freq_make:word_freq_our\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 6\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5559\n",
      "Method:                           MLE   Df Model:                           12\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                     nan\n",
      "Time:                        23:29:56   Log-Likelihood:                    nan\n",
      "converged:                       True   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
      "===============================================================================================================================\n",
      "                                                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                          nan        nan        nan        nan         nan         nan\n",
      "word_freq_make                                                     nan        nan        nan        nan         nan         nan\n",
      "word_freq_our                                                      nan        nan        nan        nan         nan         nan\n",
      "word_freq_free                                                     nan        nan        nan        nan         nan         nan\n",
      "word_freq_meeting                                                  nan        nan        nan        nan         nan         nan\n",
      "word_freq_edu                                                      nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon                                                nan        nan        nan        nan         nan         nan\n",
      "word_freq_exclamation                                              nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon:word_freq_exclamation                          nan        nan        nan        nan         nan         nan\n",
      "word_freq_hashtag                                                  nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon:word_freq_hashtag                              nan        nan        nan        nan         nan         nan\n",
      "word_freq_exclamation:word_freq_hashtag                            nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag        nan        nan        nan        nan         nan         nan\n",
      "===============================================================================================================================\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2201: RuntimeWarning: invalid value encountered in divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        X = patsy.dmatrix(formula_interactions, data=spam_previous_words)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        X = X.drop(worstp, axis=1)\n",
    "        X_names = ['Intercept'] + list(X.columns)[1:]\n",
    "        X.columns = X_names\n",
    "\n",
    "        myprobit = sm.Probit(spam['spam'], X).fit()\n",
    "\n",
    "        print(myprobit.summary())\n",
    "        p = myprobit.pvalues\n",
    "        print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1733944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5568\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1967.1\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3934.2\n",
      "Time:                        23:18:27   Pearson chi2:                 8.72e+03\n",
      "No. Iterations:                     9   Pseudo R-squ. (CS):            0.07874\n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.1164      0.047    -44.800      0.000      -2.209      -2.024\n",
      "word_freq_free           32.3828      2.251     14.389      0.000      27.972      36.794\n",
      "word_freq_semicolon     -33.1868      8.873     -3.740      0.000     -50.578     -15.795\n",
      "word_freq_exclamation     6.0833      0.653      9.323      0.000       4.804       7.362\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(mylogit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "efa37ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 6\n",
      "Logit likelihood ratio test p-value: nan\n",
      "LinkTest result                  Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1931.5\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3863.0\n",
      "Time:                        23:30:06   Pearson chi2:                 6.29e+03\n",
      "No. Iterations:                    17   Pseudo R-squ. (CS):            0.09043\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0572      0.063     -0.902      0.367      -0.182       0.067\n",
      "x1             0.5268      0.030     17.523      0.000       0.468       0.586\n",
      "x2            -0.0185      0.001    -12.629      0.000      -0.021      -0.016\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:187: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1014: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "c:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1014: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "null_logit = sm.Logit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam_previous_words)))).fit()\n",
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)\n",
    "\n",
    "linktest_result_logit = linktest_probit(mylogit)\n",
    "print(\"LinkTest result\", linktest_result_logit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b8b5cc7",
   "metadata": {},
   "source": [
    "The coeeficients of model are jointly signifficant, however, the speciffication is not correct."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a31d57b",
   "metadata": {},
   "source": [
    "### Probit\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59f59531",
   "metadata": {},
   "source": [
    "formula_interactions = \"spam ~ word_freq_make * word_freq_our  +  word_freq_free + word_freq_meeting  + word_freq_edu +  word_freq_semicolon * word_freq_exclamation * word_freq_hashtag\"\n",
    "myprobit = sm.formula.glm(formula_interactions, data=spam_previous_words, family=sm.families.Binomial(sm.genmod.families.links.probit())).fit()\n",
    "\n",
    "p = myprobit.pvalues\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e1ae79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        Z = patsy.dmatrix(formula_interactions, data=spam_previous_words)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        Z = pd.DataFrame(Z, columns=Z.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        Z = Z.drop(worstp, axis=1)\n",
    "        Z_names = ['Intercept'] + list(Z.columns)[1:]\n",
    "        Z.columns = Z_names\n",
    "\n",
    "        myprobit = sm.Probit(spam['spam'], Z).fit()\n",
    "\n",
    "        p = myprobit.pvalues\n",
    "        print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a75ee727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5559\n",
      "Method:                           MLE   Df Model:                           12\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                     nan\n",
      "Time:                        23:30:15   Log-Likelihood:                    nan\n",
      "converged:                       True   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
      "===============================================================================================================================\n",
      "                                                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                          nan        nan        nan        nan         nan         nan\n",
      "word_freq_make                                                     nan        nan        nan        nan         nan         nan\n",
      "word_freq_our                                                      nan        nan        nan        nan         nan         nan\n",
      "word_freq_free                                                     nan        nan        nan        nan         nan         nan\n",
      "word_freq_meeting                                                  nan        nan        nan        nan         nan         nan\n",
      "word_freq_edu                                                      nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon                                                nan        nan        nan        nan         nan         nan\n",
      "word_freq_exclamation                                              nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon:word_freq_exclamation                          nan        nan        nan        nan         nan         nan\n",
      "word_freq_hashtag                                                  nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon:word_freq_hashtag                              nan        nan        nan        nan         nan         nan\n",
      "word_freq_exclamation:word_freq_hashtag                            nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag        nan        nan        nan        nan         nan         nan\n",
      "===============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(myprobit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "df0db996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 5\n",
      "Probitlikelihood ratio test p-value: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14760/2484395099.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Probitlikelihood ratio test p-value:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobit_lrtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlinktest_result_probit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinktest_probit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyprobit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LinkTest result\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinktest_result_probit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14760/2035980757.py\u001b[0m in \u001b[0;36mlinktest_probit\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# Fit the binomial regression model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGLM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfamilies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfamilies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, family, offset, exposure, freq_weights, var_weights, missing, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         super(GLM, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    317\u001b[0m                                   \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexposure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexposure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m                                   \u001b[0mfreq_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'missing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0m\u001b[0;32m     93\u001b[0m                                       **kwargs)\n\u001b[0;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0m\u001b[0;32m    674\u001b[0m                  **kwargs)\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconst_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m_handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;31m# detect where the constant is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mcheck_implicit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mexog_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mMissingDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'exog contains inf or nans'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2791\u001b[0m     \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2792\u001b[0m     \"\"\"\n\u001b[1;32m-> 2793\u001b[1;33m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[0;32m   2794\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   2795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "null_probit = sm.Probit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam_previous_words)))).fit()\n",
    "probit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probitlikelihood ratio test p-value:\", probit_lrtest)\n",
    "\n",
    "linktest_result_probit = linktest_probit(myprobit)\n",
    "print(\"LinkTest result\", linktest_result_probit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce6846c8",
   "metadata": {},
   "source": [
    "Same results as for Logit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c428d60c",
   "metadata": {},
   "source": [
    "### Other goodness of fit tests\n",
    "\n",
    "As in previous study the Link Test and LR test draw attention to the logit model with interactions that was good specified and significant\n",
    "Now let us perform other tests for the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb989191",
   "metadata": {},
   "source": [
    "gof_results = mylogit.deviance\n",
    "print(\"Logit | Goodness-of-Fit Test:\")\n",
    "print(\"Logit | Deviance: \", gof_results)\n",
    "\n",
    "gof_results = myprobit.deviance\n",
    "print(\"Probit | Goodness-of-Fit Test:\")\n",
    "print(\"Probit | Deviance: \", gof_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e3ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit | Pseudo R-squared:  0.10406808092209863\n",
      "Probit | Pseudo R-squared:  0.11598148267507902\n"
     ]
    }
   ],
   "source": [
    "pseudo_r2 = 1 - (mylogit.llf / mylogit.llnull)\n",
    "print(\"Logit | Pseudo R-squared: \", pseudo_r2)\n",
    "\n",
    "pseudo_r2 = 1 - (myprobit.llf / myprobit.llnull)\n",
    "print(\"Probit | Pseudo R-squared: \", pseudo_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a331fcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Pseudo R-squared:  0.8752692031586504\n"
     ]
    }
   ],
   "source": [
    "pred_probs = result.predict()\n",
    "y_observed = result.model.endog\n",
    "\n",
    "# Round predicted probabilities to 0 or 1 based on the cutoff of 0.50\n",
    "pred_classes = np.where(pred_probs > 0.50, 1, 0)\n",
    "\n",
    "# Calculate the number of correctly classified cases\n",
    "correctly_classified = np.sum(pred_classes == y_observed)\n",
    "\n",
    "# Calculate the total number of cases\n",
    "total_cases = len(y_observed)\n",
    "\n",
    "# Calculate the count pseudo R-squared\n",
    "count_r2 = correctly_classified / total_cases\n",
    "\n",
    "# Calculate the number of predictors in the model\n",
    "p = result.df_model\n",
    "\n",
    "# Print the pseudo R-squared statistics\n",
    "print(\"Count Pseudo R-squared: \", count_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef9884",
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'word_freq_re' is not defined\n    spam ~ word_freq_all+word_freq_free+word_freq_re+word_freq_semicolon*word_freq_exclamation\n                                        ^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"eval\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         return eval(code, {}, VarLookupDict([inner_namespace]\n\u001b[0m\u001b[0;32m    166\u001b[0m                                             + self._namespaces))\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_freq_re' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14760/4178915748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Fit the logistic regression model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'spam ~ word_freq_all+word_freq_free+word_freq_re+word_freq_semicolon*word_freq_exclamation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[0m\u001b[0;32m    201\u001b[0m                                   missing=missing)\n\u001b[0;32m    202\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\formula\\formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[0m\u001b[0;32m     64\u001b[0m                                NA_action=na_action)\n\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \"\"\"\n\u001b[0;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[0m\u001b[0;32m    310\u001b[0m                                       NA_action, return_type)\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[0m\u001b[0;32m    165\u001b[0m                                       NA_action)\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[1;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelDesc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         return design_matrix_builders([formula_like.lhs_termlist,\n\u001b[0m\u001b[0;32m     67\u001b[0m                                        formula_like.rhs_termlist],\n\u001b[0;32m     68\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[1;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;31m# on some data to find out what type of data they return.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     (num_column_counts,\n\u001b[1;32m--> 693\u001b[1;33m      \u001b[0mcat_levels_contrasts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_examine_factor_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_factors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m                                                    \u001b[0mfactor_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                                                    \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36m_examine_factor_types\u001b[1;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamine_needed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactor_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mguess_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, memorize_state, data)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m         return self._eval(memorize_state[\"eval_code\"],\n\u001b[0m\u001b[0;32m    565\u001b[0m                           \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                           data)\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36m_eval\u001b[1;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0minner_namespace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVarLookupDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"transforms\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         return call_and_wrap_exc(\"Error evaluating factor\",\n\u001b[0m\u001b[0;32m    548\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                                  \u001b[0mmemorize_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_env\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m                                  origin)\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raise new_exc from e\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# In python 2, we just let the original exception escape -- better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'word_freq_re' is not defined\n    spam ~ word_freq_all+word_freq_free+word_freq_re+word_freq_semicolon*word_freq_exclamation\n                                        ^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "X['spam'] = spam_previous_words['spam']\n",
    "last_column = X.columns[-1]  # Get the name of the last column\n",
    "columns = [last_column] + list(X.columns[:-1])  # Create a new list of column names with the last column at the front\n",
    "X = X[columns]  # Reorder the columns in the DataFrame\n",
    "\n",
    "epsilon = 1e-8\n",
    "\n",
    "X = X.replace(0, epsilon)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = smf.probit(formula='spam ~ word_freq_all+word_freq_free+word_freq_re+word_freq_semicolon*word_freq_exclamation', data=X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# Get marginal effects\n",
    "margeff_overall = model.get_margeff(at='overall')\n",
    "print(margeff_overall.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1c65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_free</th>\n",
       "      <th>word_freq_semicolon</th>\n",
       "      <th>word_freq_exclamation</th>\n",
       "      <th>spam</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333333e-02</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_free  word_freq_semicolon  word_freq_exclamation  \\\n",
       "0       1.000000e-08         1.000000e-08           1.000000e-08   \n",
       "1       1.000000e-08         1.000000e-08           1.000000e-08   \n",
       "2       3.333333e-02         1.000000e-08           1.000000e-08   \n",
       "3       1.000000e-08         1.000000e-08           1.000000e-08   \n",
       "4       1.000000e-08         1.000000e-08           1.000000e-08   \n",
       "...              ...                  ...                    ...   \n",
       "5567    1.000000e-08         1.000000e-08           4.000000e-02   \n",
       "5568    1.000000e-08         1.000000e-08           1.000000e-08   \n",
       "5569    1.000000e-08         1.000000e-08           1.000000e-08   \n",
       "5570    7.142857e-02         1.000000e-08           1.000000e-08   \n",
       "5571    1.000000e-08         1.000000e-08           1.000000e-08   \n",
       "\n",
       "              spam  Intercept  \n",
       "0     1.000000e-08        1.0  \n",
       "1     1.000000e-08        1.0  \n",
       "2     1.000000e+00        1.0  \n",
       "3     1.000000e-08        1.0  \n",
       "4     1.000000e-08        1.0  \n",
       "...            ...        ...  \n",
       "5567  1.000000e+00        1.0  \n",
       "5568  1.000000e-08        1.0  \n",
       "5569  1.000000e-08        1.0  \n",
       "5570  1.000000e-08        1.0  \n",
       "5571  1.000000e-08        1.0  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
